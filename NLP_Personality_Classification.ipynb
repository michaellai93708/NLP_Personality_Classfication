{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGHoy6KpQDfZ"
   },
   "source": [
    "# 2022 COMP5046 Assignment 1\n",
    "*Make sure you change the file name with your unikey.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTf21j_oQIiD"
   },
   "source": [
    "# Readme (PLEASE DO NOT RUN ANY CODE IN SECTION 4)\n",
    "PLEASE DO NOT RUN any code in section 4 since some of the graphs/tables were made automatically from train/test trails. Running any code in section 4 may result in loss of table/graph.\n",
    "Thank you \n",
    "\n",
    "The object oriented programming codes section was not used, just simply running all codes before section 4 would do the work.\n",
    "\n",
    "In section 4.1, I found that only using glove-twitter-100 embedding produced the best weighted F1 score. Therefore, in section 1 through 3 and section 5, I used only one embedding model. However, embedding concatenation was used in section 4.1 to determine the accuracies of different word embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXbQohXLKSgO"
   },
   "source": [
    "***Visualising the comparison of different results is a good way to justify your decision.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7v4GVxo4Dom"
   },
   "source": [
    "# 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HftyG77k47Y3"
   },
   "source": [
    "## 1.0. Data Collection [DO NOT MODIFY THIS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7C4snIcNl22",
    "outputId": "aec03284-8207-4cb2-cb70-cd2b917c6296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Size of training dataset: 7808\n",
      "Size of testing dataset: 867\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "Sample Data\n",
      "LABEL: F / SENTENCE: 'Half of it is going straight to charity, another quarter going straight to scientific research, an eighth to the parkour community, a sixteenth to towards spreading information about health and...|||Find a path or suffer more.|||http://personalitycafe.com/enneagram-personality-theory-forum/85323-enneagram-type-mbti-type-compared-statistics.html yep.|||I kind of anchor on Fi and Ne makes having Ni really fun. INFP for me as they tire me out less and our views tend to align more.|||The two ESTPs I have gotten the chance to know seem to experience much more than other people who have been on the planet for the same amount of time and are quite the renaissance (wo)men.  Is this...|||I don't really have a best friend ISTP(passion-amateur group co-founder), INTJ(intellectual and various small hobbies talk), ESTP(Bro-in-law, talk about everything kind of like my INTJ friend),...|||Everyone looses their gift if they don't even consider a different perspective.|||Kansas - ISTJ|||That or if they are normally comfortable with me, such as a friend or close acquaintance, they feel the need to start talking. It's almost a trap, I've noticed for most people feel the need to expose...|||To me, your answers screamed introverted feeling. Answers 2-5, 10, 11, 14, 16, and 17 your last statement were particularly Fi-like. I'm guessing you are an intuitive and possibly and introvert...|||Could you explain your reasoning for these? I saw Mako as an F, Lin as an ES, and have Kya as an F. Never had an idea for Amon's type.|||This applies to many of these threads.|||With an INFP for over 2 years now.|||After watching tonight's episode I'm sure that Unalaq is an ENXJ. I'm not sure if it's Fe or Te at this point but the way he goes about doing and planning things seem like a Je-dom. I'm putting him...|||Parkour is my passion(but I consider it closer to a martial art than a sport). I also enjoy some running and climbing.|||I have many characters but I gravitate towards sneaky archer, Breton, and conjuration. I love doing role plays and think it's one of, if not the best way to play the game.|||ESFP seems right for Ikki. We may need Jinora to have more interactions for us to tell. Any guesses about Pema, Tenzin's wife? She said herself that she used to be very shy so I'd put I just from...|||If you don't mind, please tell me more by what you meant by this bolded part or what happened.|||I think it's fit to revive this thread seeing as the second season of Korra has started and the second episode of the season is coming up tomorrow. I'd just say beware of spoilers in new posts if you...|||I was thinking more along these lines: 83385|||Yes, a few times in friendships and other things but it was usually spurred on by the idea of not having a second chance. I've been trying to make the first move more in life as I've realized it just...|||Sorry if my wording was/is confusing or vague. Let me try to explain it better.  As for the first statement: I see the world for all it's interconnections. If you wish, visualized everything having...|||~I don't experience it as simply perceiving or creating, for me as I perceive interconnected relationships are formed and realized.   ~I don't think that I rationalize with my dominate function but...|||I think it's amusing that, in the leading position I share with an ISTP friend of mine, we both start to embrace our shadows. I Think that's been my growing point lately, embracing my shadow. We're...|||I would suggest introspection and relying on your sense of self over tests and I highly suggest looking into the cognitive functions. ISTJ is the complete opposite of INFJ.|||I definitely agree with others on the US- It's pretty good for an INFJ if you find your niche.  I say the Midwest is generally SJ with women expected to be F and men to be T. It's nice but annoying....|||Please explain|||I think my own eye movements have almost been changed because of where I was usually placed when talking to someone in normal conversations. See, when I was young I ended up getting permanent spot in...|||Judgmental, critical, somewhat narcissistic, stubborn, possessive, Fe-ishly manipulative, and I have ego issues. Take that with a grain of salt.|||Yes, very much so. I love Spanish so far.|||I have a huge folder of these types of images.|||Aquarian It was just my guess, it doesn't need that much merit. Personally, I think Se is the hardest function to describe because it is so in the moment.|||Sorry, double post because of connectivity weirdness.|||I don't know if this has been posted before or if a thread about curses would be the best place but it'll do just fine. The important part is post #79, the giant wall of text. I think most of it was...|||If anything, imo, Ni would be how objects are interconnected. If I were to follow closely to your model: Introverted Intuition: Understanding how objects are connected Extraverted Intuition:...|||Sometimes you just don't see them :ninja: Seriously, I thought I was alone in a small town but I was surprised after training for a couple months.  You can easily learn and train by yourself, you...|||82063 Stuff by Andy Day, not only do I like it because it is the stuff of my passion but that new perspective of our surroundings that it brings. This is a great example of that. All those people...|||Sorry for the quality, my relative only gave me a physical copy, it's a picture of a picture. This is my INFP girlfriend of two years and me.|||If I am with my SO I almost need physical contact in some way.|||I pretty much have a guru dream that involves my SP wannabe passion. Around people I am close to I totally put on the gypsy king face, people are just so interesting. Hahaha can't stop laughing at ...|||I agree this this post very much, I just can't shake that vibe. To me it feels like you are an INTP who strongly identifies with INFJs. I think if you want a sound answer form yourself and others we...|||I do pretty well in emergencies, I do very well compared to normal conditions in my opinion. I feel like I become the ideal version of myself, for the most part. It's hard to describe but it's like...|||I have a very close INTJ friend. The Te Fe difference is acknowledged very well and I'd say that both of our tertiary functions are well developed which helps a ton. He does not show it often but he...|||Being alone and/or doing something physical that I can naturally and reactively do without thinking or little thought.|||Pretty much this|||If I wear shoes or socks to bed and my feet are not on my bed I will wake up as if I was falling. 2/3 of the time this happens. Any other dreams that I remember(I don't remember most of my dreams...|||This one still gets me.  What I meant to say was Pass the salt but what I really said was You b****, you ruined my life|||I'm sorry, but I find them so funny because I use them for good reason. They make people uncomfortable at first but then, slowly, make people more comfortable with the idea that people are different...|||XSFJ Mother, ISTJ father, and an XNFJ sister. Yep.|||I love dark jokes, especially racists/stereotypical jokes.'\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id = '16g474hdNsaNx0_SnoKuqj2BuwSEGdnbt'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('training_data.csv')  \n",
    "\n",
    "id = '1-7hj0sF3Rc5G6POKdkpbDXm_Q6BWFDPU'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('testing_data.csv')  \n",
    "\n",
    "import pandas as pd\n",
    "training_data = pd.read_csv(\"/content/training_data.csv\")\n",
    "testing_data = pd.read_csv(\"/content/testing_data.csv\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Size of training dataset: {0}\".format(len(training_data)))\n",
    "print(\"Size of testing dataset: {0}\".format(len(testing_data)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "print(\"Sample Data\")\n",
    "print(\"LABEL: {0} / SENTENCE: {1}\".format(training_data.iloc[-1,0], training_data.iloc[-1,1]))\n",
    "print(\"------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "WIHEbmSQp3fh",
    "outputId": "2b0ef1c7-4873-4aaa-d702-d65ab15e0311"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7ccd6d27-4b91-4b65-a90c-cbfd99799bde\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ccd6d27-4b91-4b65-a90c-cbfd99799bde')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7ccd6d27-4b91-4b65-a90c-cbfd99799bde button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7ccd6d27-4b91-4b65-a90c-cbfd99799bde');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  type                                              posts\n",
       "0    F  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1    T  'I'm finding the lack of me in these posts ver...\n",
       "2    T  'Good one  _____   https://www.youtube.com/wat...\n",
       "3    T  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4    T  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the data in the csv file, which has two columns: \n",
    "# (1)type - label of the post (2)posts - the corresponding post content\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0SvGBOm9DvR_"
   },
   "outputs": [],
   "source": [
    "# Extract the labels and posts and store into List\n",
    "# Get the list of training data (posts)\n",
    "training_posts=training_data['posts'].tolist()\n",
    "# Get the list of corresponding labels for the training data (posts)\n",
    "training_labels=training_data['type'].tolist()\n",
    "# Get the list of testing data (posts)\n",
    "testing_posts=testing_data['posts'].tolist()\n",
    "# Get the list of corresponding labels for the testing data (posts)\n",
    "testing_labels=testing_data['type'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9gBSgBCQh24"
   },
   "source": [
    "## 1.1. URL Removal\n",
    "*related to the section 4.2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emyl1lWxGr12",
    "outputId": "0ac02768-5423-482e-83b0-cfff3246a0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' does, indeed, help. To answer the question, my IQ is 129, and it was professionally administered. But, it doesn't mean anything to me--I don't need a number to tell me I'm intelligent, I...|||Shall I play you a song on the world's smallest violin?|||I really don't get how you guys think she's an introvert. She's said many times about how extroverted she is, and she was voted Most Talkative by her high school. I can see an introvert being...|||Assuming morality is absolute, can you explain to me the absolute best moral choice out of every situation? I'm assuming you cannot, and on who's authority should we accept these truths? It cannot be...|||Hello all,  I originally joined this site in late 2009, and I lurked for many months before. I had just turned 19 and started college , in search of myself, and I used this forum to help discover...|||1. Log in after a week or so of not being on here. 2. Look at INFJ forum, sees that all the new threads are already ones that I've seen and discussed in the past. 3. Check the new posts in case I...|||I hope everyone realizes the difference between a nice guy and a, well, nice guy.|||www.youtube.com/watch?v=DOX9l4Ys7NY|||I would retire my account since I don't ever come on here anymore (and I don't really care about MBTI anymore), but why put an unnecessary restriction on myself?|||I'm not a virgin. In some ways, I still wish I was--I lost my virginity to someone who I wasn't in love with. The girl I'm with right now is, and if it weren't for that one girl, I would be too and...|||I'm 21. I'm young, amirite?|||Having the feeling of being alone.  Being able to tell a lot about a person just by their energy. It's almost like I've known them for years. And then, if they find this out, it freaks them out....||| think it might be more of a biological thing and how you were raised more than how it is based on your type, but I can see how type could play a part.  As for me....yeah, I'm nowhere near an...|||I suppose I still am, but I've lowered my standards so much to where I date people I don't even like, probably just to not feel alone. I'm a little disgusted with myself at the moment.||| know what you mean. I've had this same problem for the longest time, and I too can seem to spark relationships better over text. Weird. But, anyways, I've just forced myself to be a little more...|||I can imagine most INFJs can relate to this.    trust test results. That being said, I could very well be an INFJ type 3.|||My views have always been that I will never have sex with someone that I know is just gonna lead to sex and that's it. Up to this point, I've followed through to that, because I can't imagine giving...|||For me, like most of you, it comes out very early on, but I try to control my tongue for as long as I can, so I hardly ever say it at all, at least intentionally. At the beginning, I think, it's less...|||Right now I'm debating whether I'm an ENTP or INFJ.  Sounds very strange, but both of them fit me.|||Who doesn't get a little genocidal every now and then?|||Walter may actually be an INFJ, not an INTJ. The reason I say this is that it's VERY clear to me that Gus is an INTJ, but there seems to be some variance between them. I'll be able to explain more...|||Bout damn time!|||I'm a dude, so it's kind of embarrassing that I like this show, but it ain't too bad. The only two I know are Lorelai and Rory, and they're ESFP and INFJ/ISFJ, respectively.|||   would say you're an ESFP or ENFP, probably leaning stronger with ESFP over ENFP.  You're not introverted. At all.|||Are you seriously basing your dating life based on some Personality Theory that may or may not be bullshit?|||I seriously hope this is a joke thread. It's getting that bad that I can't tell if someone is trolling, or just flat out fucking stupid.  As for who's going to win--unless Romeny wins the...|||Congratulations??|||I never made one in the first place, so.....hey?  I'm not sure why I'm even making this, as I'm probably just gonna retire this account soon anyway, but, ya know, just thought I'd make one.|||You're typism.  Honestly, I don't really have a specific type that annoys me. Stupid annoys me, not type.  That being said, for the love of FSM and all that is holy, I am NEVER, EVER, EVER...||| this isn't the first time you've posted something like this in the two years I've been here, it's in all likelihood depression, dude. I had the same symptoms for, oh, 7 years or so, and when I...|||I'm my own partner.|||EDIT I guess that's what I get for not reading the whole post.|||Can I come tuck you in?|||You're probably a 3, then.  I'm a type three myself, and I fall into the more reserved category with most people. I would still consider myself extroverted, but people who talk nonstop actually get...||| common. I'm a 3, but a 3w4, not a 3w2.|||Not at all ENTP. I'd say ISTP, or ESTP if that doesn't work.||| the words right out of my mouth.|||Just so everyone's clear, getting a percentage on a MBTI doesn't mean you're 75% introvert. It means you can be pretty confident you're an introvert.  Back on topic, I'm pretty much certain that...|||Yeah, same thing happened to me. Fuckers.  Dear stupid people--just because I don't show it doesn't mean I'm not judging you. At least you keep me entertained.  Excuse my misogyny, but fuck...|||Tell me about it. But, ironically, I'm dating a girl from California who moved over here a while ago, and I met her through Ok Cupid. Didn't actually expect that thing to produce results, but it has!...|||I'd say Obama is most definitely an ENFJ. Speaking to common values, but sticking to his own internal vision, etc.  Sarah Palin--ESFJ  Ronald Reagan--Hard to tell. Probably ESTP in my opnion. ...'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "training_posts_no_url, testing_posts_no_url = [], []\n",
    "for i in training_posts:\n",
    "    result = re.sub(r\"http\\S+\", \"\", i)\n",
    "    training_posts_no_url.append(result)\n",
    "for j in testing_posts:\n",
    "    result = re.sub(r\"http\\S+\", \"\", j)\n",
    "    testing_posts_no_url.append(result)\n",
    "print(testing_posts_no_url[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzLAO5a25qzS"
   },
   "source": [
    "## 1.2. Preprocess data (e.g. Stop words, Stemming)\n",
    "*related to the section 4.2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jl7t5Vqo5_gq",
    "outputId": "746ad45b-3773-4a6b-e45d-9fd5d46c9db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "['F' 'T']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as sw\n",
    "stop_words = sw.words('english')\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def remove_number(x):\n",
    "    x =  re.sub(r'[0-9]+', '', x)\n",
    "    return x\n",
    "def remove_punctuation_re(x):\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    return x\n",
    "def pre_process(input_list):\n",
    "    # Converting to lower case\n",
    "    lower = [s.lower() for s in input_list]\n",
    "    # Removing number \n",
    "    remove_num = [remove_number(s) for s in lower]\n",
    "    # Removing punctuation\n",
    "    remove_pun = [remove_punctuation_re(s) for s in remove_num]\n",
    "    # Tokenization \n",
    "    Tokenized = [word_tokenize(s) for s in remove_pun]\n",
    "    # Removing stop words\n",
    "    remove_sw = []\n",
    "    for tokens in Tokenized:\n",
    "        filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "        remove_sw.append(filtered_sentence)\n",
    "    # Stemming\n",
    "    result = []\n",
    "    for tokens in remove_sw:\n",
    "        stemmed = [stemmer.stem(s) for s in tokens]\n",
    "        result.append(stemmed)\n",
    "    # Lemmatization\n",
    "    #result = []\n",
    "    #for tokens in result_1:\n",
    "    #    lemma_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
    "    #    result.append(lemma_sentence)\n",
    "    return result\n",
    "# Label Encoding\n",
    "unique_labels = np.unique(training_labels)\n",
    "lEnc = LabelEncoder()\n",
    "training_labels_encoded = lEnc.fit_transform(training_labels)\n",
    "testing_labels_encoded = lEnc.transform(testing_labels)\n",
    "n_class = len(unique_labels)\n",
    "print(unique_labels)\n",
    "print(lEnc.transform(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O1ZS7laCxEAN"
   },
   "outputs": [],
   "source": [
    "training_posts_no_url_processed = pre_process(training_posts_no_url)\n",
    "testing_posts_no_url_processed = pre_process(testing_posts_no_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W65YgG-YVFFS"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sAZNIg5927R"
   },
   "source": [
    "# 2 - Input Representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daDvAftceIvr"
   },
   "source": [
    "## 2.1. Word Embedding Construction\n",
    "*related to the section 4.1 and 4.3*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw8I1QBk-EhG",
    "outputId": "b15cd053-c37d-4b03-d1ca-d6358fa455d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7808\n",
      "867\n",
      "8675\n"
     ]
    }
   ],
   "source": [
    "print(len(training_posts_no_url_processed))\n",
    "print(len(testing_posts_no_url_processed))\n",
    "emb_list = []\n",
    "for i in training_posts_no_url_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_no_url_processed:\n",
    "    emb_list.append(j)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6VO64b8gxHfG"
   },
   "outputs": [],
   "source": [
    "# Training Embedding model 1\n",
    "from gensim.models import Word2Vec\n",
    "word_emb_model_1 = Word2Vec(emb_list, size=100, window=5, min_count=0, workers=-1, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNys5HOdISK-"
   },
   "source": [
    "## 2.2. Pretrained Word Embedding\n",
    "*related to the section 4.3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ae8i7Z2kIef-"
   },
   "outputs": [],
   "source": [
    "# Download Embedding model from gensim\n",
    "import gensim.downloader as api\n",
    "word_emb_model_2 = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ap96aeGlIk"
   },
   "source": [
    "## 2.3. Input Concatenation\n",
    "*related to the section 4.3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jw_N9J7Tx1MI"
   },
   "outputs": [],
   "source": [
    "def concat(word_emb_model_1, word_emb_model_2):\n",
    "    emb_dim = word_emb_model_1.vector_size + word_emb_model_2.vector_size\n",
    "    emb_table = []\n",
    "    for i, word in enumerate(word_list):\n",
    "        if word in word_emb_model_1 and word in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate((word_emb_model_1[word], word_emb_model_2[word]),0))\n",
    "        elif word in word_emb_model_1 and word not in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate((word_emb_model_1[word], [0]*word_emb_model_2.vector_size),0))\n",
    "        elif word in word_emb_model_1 and word not in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate(([0]*word_emb_model_1.vector_size, word_emb_model_2[word]),0))\n",
    "        else:\n",
    "            emb_table.append([0]*emb_dim)\n",
    "    emb_table = np.array(emb_table)\n",
    "    return emb_table, emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i2CUCL1cGlI2"
   },
   "outputs": [],
   "source": [
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "\n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "emb_dim = word_emb_model_2.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if word in word_emb_model_2:\n",
    "        emb_table.append(word_emb_model_2[word])\n",
    "    else:\n",
    "        emb_table.append([0]*emb_dim)\n",
    "emb_table = np.array(emb_table)\n",
    "    \n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded\n",
    "\n",
    "train_pad_encoded_no_url = encode_and_add_padding(training_posts_no_url_processed, seq_length, word_index )\n",
    "test_pad_encoded_no_url = encode_and_add_padding(testing_posts_no_url_processed, seq_length, word_index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIu_lkJwQ55g"
   },
   "source": [
    "# 3 - Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpYCL17JKZxl"
   },
   "source": [
    "### 3.1. Build Sequence Model (Bi-directional model)\n",
    "*related to the section 4.4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "13eCtR_SLUG6"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BaOiaGRLW7R"
   },
   "source": [
    "### 3.2. Train Sequence Model (Bi-directional model)\n",
    "\n",
    "*related to the section 4.4*\n",
    "\n",
    "Note that it will not be marked if you do not display the Training Loss and the Number of Epochs in the Assignment 1 ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVQnUSX1LZ6C",
    "outputId": "86009282-fb4e-4fe8-b507-0c00765a87af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.68408, train_acc: 0.55\n",
      "Epoch: 20, loss: 0.67492, train_acc: 0.58\n",
      "Epoch: 30, loss: 0.66023, train_acc: 0.61\n",
      "Epoch: 40, loss: 0.62605, train_acc: 0.64\n",
      "Epoch: 50, loss: 0.60115, train_acc: 0.67\n",
      "Epoch: 60, loss: 0.58173, train_acc: 0.69\n",
      "Epoch: 70, loss: 0.56929, train_acc: 0.70\n",
      "Epoch: 80, loss: 0.55278, train_acc: 0.72\n",
      "Epoch: 90, loss: 0.54061, train_acc: 0.73\n",
      "Epoch: 100, loss: 0.52580, train_acc: 0.74\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model, '/content/bi_LSTM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4mpRpocePLN"
   },
   "source": [
    "# 4 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbLBzHObsvvM"
   },
   "source": [
    "## 4.1. Word Embedding Evaluation\n",
    "You are to apply Semantic-Syntactic word relationship tests for the trained word embeddings and visualise the result of Semantic-Syntactic word relationship tests.\n",
    "Note that it will not be marked if you do not display it in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSIUsb7qtQEf"
   },
   "source": [
    "(*Please show your empirical evidence and justification*)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCrcXwcGsuuo",
    "outputId": "b4b93e19-a8b0-4cbb-d67d-4aa05e0d3ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GloVe'...\n",
      "remote: Enumerating objects: 606, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 606 (delta 5), reused 7 (delta 2), pack-reused 592\u001b[K\n",
      "Receiving objects: 100% (606/606), 224.91 KiB | 1.80 MiB/s, done.\n",
      "Resolving deltas: 100% (343/343), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/stanfordnlp/GloVe.git\n",
    "import numpy as np\n",
    "def evaluate_vectors(W, vocab, prefix='./eval/question-data/'):\n",
    "    \"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"\n",
    "    filenames = [\n",
    "        'capital-common-countries.txt', 'capital-world.txt', 'currency.txt',\n",
    "        'city-in-state.txt', 'family.txt', 'gram1-adjective-to-adverb.txt',\n",
    "        'gram2-opposite.txt', 'gram3-comparative.txt', 'gram4-superlative.txt',\n",
    "        'gram5-present-participle.txt', 'gram6-nationality-adjective.txt',\n",
    "        'gram7-past-tense.txt', 'gram8-plural.txt', 'gram9-plural-verbs.txt',\n",
    "        ]\n",
    "    split_size = 100\n",
    "    correct_sem = 0; \n",
    "    correct_syn = 0;\n",
    "    correct_tot = 0\n",
    "    count_sem = 0; \n",
    "    count_syn = 0; \n",
    "    count_tot = 0 \n",
    "    full_count = 0 \n",
    "    for i in range(len(filenames)):\n",
    "        with open('%s/%s' % (prefix, filenames[i]), 'r') as f:\n",
    "            full_data = [line.rstrip().split(' ') for line in f]\n",
    "            full_count += len(full_data)\n",
    "            data = [x for x in full_data if all(word in vocab for word in x)]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        indices = np.array([[vocab[word] for word in row] for row in data])\n",
    "        ind1, ind2, ind3, ind4 = indices.T\n",
    "        predictions = np.zeros((len(indices),))\n",
    "        num_iter = int(np.ceil(len(indices) / float(split_size)))\n",
    "        for j in range(num_iter):\n",
    "            subset = np.arange(j*split_size, min((j + 1)*split_size, len(ind1)))\n",
    "            pred_vec = (W[ind2[subset], :] - W[ind1[subset], :]\n",
    "                +  W[ind3[subset], :])\n",
    "            dist = np.dot(W, pred_vec.T)\n",
    "            for k in range(len(subset)):\n",
    "                dist[ind1[subset[k]], k] = -np.Inf\n",
    "                dist[ind2[subset[k]], k] = -np.Inf\n",
    "                dist[ind3[subset[k]], k] = -np.Inf\n",
    "            predictions[subset] = np.argmax(dist, 0).flatten()\n",
    "        val = (ind4 == predictions) \n",
    "        count_tot = count_tot + len(ind1)\n",
    "        correct_tot = correct_tot + sum(val)\n",
    "        if i < 5:\n",
    "            count_sem = count_sem + len(ind1)\n",
    "            correct_sem = correct_sem + sum(val)\n",
    "        else:\n",
    "            count_syn = count_syn + len(ind1)\n",
    "            correct_syn = correct_syn + sum(val)        \n",
    "    return correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count\n",
    "\n",
    "def emb_eva(directory):\n",
    "    with open(directory, 'r') as f:\n",
    "      vectors = {}\n",
    "      for line in f.readlines()[1:]:\n",
    "        vals = line.rstrip().split(' ')\n",
    "        vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
    "    vocab_words=list(vectors.keys())\n",
    "    vocab_size = len(vocab_words)\n",
    "    vocab = {w: idx for idx, w in enumerate(vocab_words)}\n",
    "    ivocab = {idx: w for idx, w in enumerate(vocab_words)}\n",
    "    vector_dim = len(vectors[ivocab[0]])\n",
    "    W = np.zeros((vocab_size, vector_dim))\n",
    "    for word, v in vectors.items():\n",
    "        if word == '<unk>':\n",
    "            continue\n",
    "        W[vocab[word], :] = v\n",
    "    W_norm = np.zeros(W.shape)\n",
    "    d = (np.sum(W ** 2, 1) ** (0.5))\n",
    "    W_norm = (W.T / d).T\n",
    "    correct_sem, correct_syn, correct_tot, count_sem, count_syn, count_tot, full_count = evaluate_vectors(W_norm, vocab, prefix='/content/GloVe/eval/question-data')\n",
    "    sem_acc = (100 * correct_sem / float(count_sem))\n",
    "    syn_acc = (100 * correct_syn / float(count_syn))\n",
    "    total_acc = (100 * correct_tot / float(count_tot))\n",
    "    return (sem_acc, syn_acc, total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6Enzf8Q04H8",
    "outputId": "d70b7295-e7cb-4012-a05a-f7e9924118d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Skip Gram size 20 & window size 5\n",
      "15.210355987055015 7.432762836185819 8.453695836873408\n",
      "Word2Vec Skip Gram size 50 & window size 5\n",
      "23.948220064724918 14.572127139364303 15.802888700084962\n",
      "Word2Vec Skip Gram size 100 & window size 5\n",
      "24.271844660194176 17.066014669926652 18.011894647408667\n",
      "Word2Vec Skip Gram size 200 & window size 5\n",
      "24.919093851132686 18.141809290953546 19.03143585386576\n",
      "Word2Vec Skip Gram size 400 & window size 5\n",
      "22.653721682847895 17.750611246943766 18.394222599830076\n",
      "Word2Vec Skip Gram size 100 & window size 5\n",
      "25.566343042071196 18.82640586797066 19.711129991503824\n",
      "Word2Vec Skip Gram size 100 & window size 10\n",
      "25.24271844660194 12.51833740831296 14.188615123194563\n",
      "Word2Vec Skip Gram size 100 & window size 20\n",
      "23.948220064724918 7.970660146699267 10.067969413763807\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "dimension = [20, 50, 100, 200, 400]\n",
    "window_size = [5, 10, 20]\n",
    "sem_dim, syn_dim, total_dim = [], [], []\n",
    "sem_win, syn_win, total_win = [], [], []\n",
    "for i in dimension:\n",
    "    print(\"Word2Vec Skip Gram size {} & window size 5\".format(i))\n",
    "    model = Word2Vec(training_posts_no_url_processed + testing_posts_no_url_processed,\n",
    "                         size=i, window=5, min_count=5, workers=2, sg=1)\n",
    "    \n",
    "    model.wv.save_word2vec_format(\"/content/w2v_\"+str(i)+\"_5.txt\", \n",
    "                                  binary = False)\n",
    "    sem_acc, syn_acc, total_acc = emb_eva(\"/content/w2v_\"+str(i)+\"_5.txt\")\n",
    "    print(sem_acc, syn_acc, total_acc)\n",
    "    sem_dim.append(sem_acc)\n",
    "    syn_dim.append(syn_acc)\n",
    "    total_dim.append(total_acc)\n",
    "\n",
    "\n",
    "for j in window_size:\n",
    "    print(\"Word2Vec Skip Gram size 100 & window size {}\".format(j))\n",
    "    model = Word2Vec(training_posts_no_url_processed + testing_posts_no_url_processed,\n",
    "                         size=100, window=j, min_count=5, workers=2, sg=1)\n",
    "    model.wv.save_word2vec_format(\"/content/w2v_100_\"+str(j)+\".txt\", \n",
    "                                  binary = False)\n",
    "    sem_acc, syn_acc, total_acc = emb_eva(\"/content/w2v_100_\"+str(j)+\".txt\")\n",
    "    print(sem_acc, syn_acc, total_acc)\n",
    "    sem_win.append(sem_acc)\n",
    "    syn_win.append(syn_acc)\n",
    "    total_win.append(total_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq_p4L8HN7vK",
    "outputId": "f0ebc9d8-a6a9-495f-8cba-489c1c488262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy vs Dimension\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Model               |   Dimension |   Window size | Sem.   | Syn.   | Total   |\n",
      "+=====================+=============+===============+========+========+=========+\n",
      "| Fast Text Skip Gram |          20 |             5 | 15.21% | 7.43%  | 8.45%   |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |          50 |             5 | 23.95% | 14.57% | 15.80%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |         100 |             5 | 24.27% | 17.07% | 18.01%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |         200 |            10 | 24.92% | 18.14% | 19.03%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |         400 |            10 | 22.65% | 17.75% | 18.39%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Accuracy vs Window size\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Model               |   Dimension |   Window size | Sem.   | Syn.   | Total   |\n",
      "+=====================+=============+===============+========+========+=========+\n",
      "| Fast Text Skip Gram |         100 |             5 | 25.57% | 18.83% | 19.71%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |         100 |            10 | 25.24% | 12.52% | 14.19%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n",
      "| Fast Text Skip Gram |         100 |            20 | 23.95% | 7.97%  | 10.07%  |\n",
      "+---------------------+-------------+---------------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Accuracy vs Dimension\")\n",
    "mydata = [\n",
    "          [\"Fast Text Skip Gram\", \"20\", \"5\", \n",
    "           \"{:.2f}%\".format(sem_dim[0]), \"{:.2f}%\".format(syn_dim[0]), \n",
    "           \"{:.2f}%\".format(total_dim[0])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"50\", \"5\", \n",
    "           \"{:.2f}%\".format(sem_dim[1]), \"{:.2f}%\".format(syn_dim[1]), \n",
    "           \"{:.2f}%\".format(total_dim[1])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"100\", \"5\", \n",
    "           \"{:.2f}%\".format(sem_dim[2]), \"{:.2f}%\".format(syn_dim[2]), \n",
    "           \"{:.2f}%\".format(total_dim[2])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"200\", \"10\", \n",
    "           \"{:.2f}%\".format(sem_dim[3]), \"{:.2f}%\".format(syn_dim[3]), \n",
    "           \"{:.2f}%\".format(total_dim[3])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"400\", \"10\", \n",
    "           \"{:.2f}%\".format(sem_dim[4]), \"{:.2f}%\".format(syn_dim[4]), \n",
    "           \"{:.2f}%\".format(total_dim[4])\n",
    "           ]\n",
    "]\n",
    "head = [\"Model\", \"Dimension\", \"Window size\", \"Sem.\", \"Syn.\", \"Total\"]\n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))\n",
    "print(\"\")\n",
    "print(\"==\" * 40)\n",
    "print(\"\")\n",
    "print(\"Accuracy vs Window size\")\n",
    "mydata_win = [\n",
    "          [\"Fast Text Skip Gram\", \"100\", \"5\", \n",
    "           \"{:.2f}%\".format(sem_win[0]), \"{:.2f}%\".format(syn_win[0]), \n",
    "           \"{:.2f}%\".format(total_win[0])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"100\", \"10\", \n",
    "           \"{:.2f}%\".format(sem_win[1]), \"{:.2f}%\".format(syn_win[1]), \n",
    "           \"{:.2f}%\".format(total_win[1])\n",
    "           ],\n",
    "          [\"Fast Text Skip Gram\", \"100\", \"20\", \n",
    "           \"{:.2f}%\".format(sem_win[2]), \"{:.2f}%\".format(syn_win[2]), \n",
    "           \"{:.2f}%\".format(total_win[2])\n",
    "           ]\n",
    "]\n",
    "head = [\"Model\", \"Dimension\", \"Window size\", \"Sem.\", \"Syn.\", \"Total\"]\n",
    "# display table\n",
    "print(tabulate(mydata_win, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "32NxYMqRz-2S",
    "outputId": "b386d005-a712-4b3f-e4a9-8ab234ec986d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "xpoints = np.array([20, 50, 100, 200, 400])\n",
    "y_sem = np.array(sem_dim)\n",
    "y_syn = np.array(syn_dim)\n",
    "y_total = np.array(total_dim)\n",
    "plt.plot(xpoints, y_sem, color = 'r', label = \"Semantic\", marker = \"^\")\n",
    "plt.plot(xpoints, y_syn, color = 'g', label = \"Synatatic\", marker = \"s\")\n",
    "plt.plot(xpoints, y_total, color = 'blue', label = \"Overall\", marker = \"o\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Accuracy vs Dimension\")\n",
    "plt.xlabel('Dimension of the vectors') \n",
    "plt.ylabel('Accuracy in %') \n",
    "plt.show()\n",
    "\n",
    "xpoints = 5, 10, 20\n",
    "y_sem = np.array(sem_win)\n",
    "y_syn = np.array(syn_win)\n",
    "y_total = np.array(total_win)\n",
    "plt.plot(xpoints, y_sem, color = 'r', label = \"Semantic\", marker = \"^\")\n",
    "plt.plot(xpoints, y_syn, color = 'g', label = \"Synatatic\", marker = \"s\")\n",
    "plt.plot(xpoints, y_total, color = 'blue', label = \"Overall\", marker = \"o\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Accuracy vs Window size\")\n",
    "plt.xlabel('Window size') \n",
    "plt.ylabel('Accuracy in %') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlyjR_QCEv8o"
   },
   "source": [
    "As shown in the figures. In terms of the dimension of embeddings vectors, the accuracies increased rapidly from size 0 to 100. The larger the vector dimension, the more aspects of the words can be expressed, therefore higher the accuracies. While with dimension sizes larger than 100, the accuracy improvements were demolished. Which was the problem Mikolov and his team faced, which they solved by increasing the size of training data while increasing the vector dimension (Mikolov et al., 2013). Explanations for this problem might be that some features may carry false information when training with large dimension sizes. The small size of the training data might also contribute since some words in the test set had not appeared in the training set.<br>\n",
    "In terms of window size, larger window size led to lower accuracies. According to Levy and Goldberg, one of the explanations could be that a larger window size would lead the word embedding to be more topic-related (Levy & Goldberg, 2014). Meaning that the embedding trained with a larger window size would result in an embedding that is more MBTI related. Yet, the topics were not significantly MBTI-related for the test set. They were more about the words themselves, which caused embedding trained with larger window sizes to result in lower accuracies. \n",
    "1.   Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. \n",
    "2.   Levy, O., &amp; Goldberg, Y. (2014). Dependency-based word embeddings. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). https://doi.org/10.3115/v1/p14-2050 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEW1zMgVMREr"
   },
   "source": [
    "## 4.2. Performance Evaluation with Data Processing Techiques\n",
    "\n",
    "\n",
    "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
    "Note that it will not be marked if you do not display it in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVCF0bwTtRS0"
   },
   "source": [
    "(*Please show your empirical evidence and justification*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LPHCb-bneTI9",
    "outputId": "ccbee28a-dea6-4356-c5a7-249c7910c4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       467\n",
      "           1       0.59      0.61      0.60       400\n",
      "\n",
      "    accuracy                           0.62       867\n",
      "   macro avg       0.62      0.62      0.62       867\n",
      "weighted avg       0.62      0.62      0.62       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\"/content/bi_LSTM.pt\")\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHl53DZTM0OZ"
   },
   "outputs": [],
   "source": [
    "training_posts_processed = pre_process(training_posts)\n",
    "testing_posts_processed = pre_process(testing_posts)\n",
    "print(len(training_posts_processed))\n",
    "print(len(testing_posts_processed))\n",
    "emb_list = []\n",
    "for i in training_posts_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_processed:\n",
    "    emb_list.append(j)\n",
    "print(len(emb_list))\n",
    "from gensim.models import FastText\n",
    "word_emb_model_1_with_url = FastText(emb_list, size=200, window=5, min_count=0, workers=-1, sg=1)\n",
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "word_list = list(word_set) \n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1\n",
    "import numpy as np\n",
    "emb_dim = word_emb_model_1_with_url.vector_size + word_emb_model_2.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if word in word_emb_model_1_with_url and word in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], word_emb_model_2[word]),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], [0]*word_emb_model_2.vector_size),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate(([0]*word_emb_model_1_with_url.vector_size, word_emb_model_2[word]),0))\n",
    "    else:\n",
    "        emb_table.append([0]*emb_dim)\n",
    "emb_table = np.array(emb_table)\n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded\n",
    "\n",
    "train_pad_encoded = encode_and_add_padding(training_posts_processed, seq_length, word_index )\n",
    "test_pad_encoded= encode_and_add_padding(testing_posts_processed, seq_length, word_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFc7PosOesvc"
   },
   "outputs": [],
   "source": [
    "input_torch = torch.from_numpy(np.array(train_pad_encoded)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model, '/content/bi_LSTM_with_url.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OwTnA-pI0JH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM with url\n",
    "model_without_url= torch.load('/content/bi_LSTM_with_url.pt')\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9CSf8yVfkOD"
   },
   "outputs": [],
   "source": [
    "'''import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as sw\n",
    "stop_words = sw.words('english')\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def remove_number(x):\n",
    "    x =  re.sub(r'[0-9]+', '', x)\n",
    "    return x\n",
    "def remove_punctuation_re(x):\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    return x\n",
    "def pre_process_2(input_list):\n",
    "    # Converting to lower case\n",
    "    lower = [s.lower() for s in input_list]\n",
    "    # Removing number \n",
    "    remove_num = [remove_number(s) for s in lower]\n",
    "    # Removing punctuation\n",
    "    remove_pun = [remove_punctuation_re(s) for s in remove_num]\n",
    "    # Tokenization \n",
    "    Tokenized = [word_tokenize(s) for s in remove_pun]\n",
    "    # Removing stop words\n",
    "    #for tokens in Tokenized:\n",
    "    #    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "    #    remove_sw.append(filtered_sentence)\n",
    "    # Stemming\n",
    "    result_1 = []\n",
    "    for tokens in Tokenized:\n",
    "        stemmed = [stemmer.stem(s) for s in tokens]\n",
    "        result_1.append(stemmed)\n",
    "    # Lemmatization\n",
    "    result = []\n",
    "    for tokens in result_1:\n",
    "        lemma_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
    "        result.append(lemma_sentence)\n",
    "    return result\n",
    "\n",
    "training_posts_no_url_no_sw_processed = pre_process_2(training_posts_no_url)\n",
    "testing_posts_no_url_no_sw_processed = pre_process_2(testing_posts_no_url)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbGnw5eggbsd"
   },
   "outputs": [],
   "source": [
    "'''emb_list = []\n",
    "for i in training_posts_no_url_no_sw_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_no_url_no_sw_processed:\n",
    "    emb_list.append(j)\n",
    "print(len(emb_list))\n",
    "from gensim.models import FastText\n",
    "word_emb_model_1_with_url = FastText(emb_list, size=200, window=5, min_count=0, workers=-1, sg=1)\n",
    "\n",
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "\n",
    "word_list = list(word_set) \n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1\n",
    "\n",
    "import numpy as np\n",
    "emb_dim = word_emb_model_1_with_url.vector_size + word_emb_model_2.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if word in word_emb_model_1_with_url and word in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], word_emb_model_2[word]),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], [0]*word_emb_model_2.vector_size),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate(([0]*word_emb_model_1_with_url.vector_size, word_emb_model_2[word]),0))\n",
    "    else:\n",
    "        emb_table.append([0]*emb_dim)\n",
    "emb_table = np.array(emb_table)\n",
    "\n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded\n",
    "\n",
    "train_pad_encoded = encode_and_add_padding(training_posts_no_url_no_sw_processed, seq_length, word_index )\n",
    "test_pad_encoded = encode_and_add_padding(testing_posts_no_url_no_sw_processed, seq_length, word_index )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQgJVB-qjvA-"
   },
   "outputs": [],
   "source": [
    "'''unique_labels = np.unique(training_labels)\n",
    "lEnc = LabelEncoder()\n",
    "training_labels_encoded = lEnc.fit_transform(training_labels)\n",
    "testing_labels_encoded = lEnc.transform(testing_labels)\n",
    "n_class = len(unique_labels)\n",
    "print(unique_labels)\n",
    "print(lEnc.transform(unique_labels))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReC6ALcsg0bO"
   },
   "outputs": [],
   "source": [
    "'''print(type(train_pad_encoded))\n",
    "import torch\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "\n",
    "\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model, '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_without_url_without_sw_removal.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeF53WdlkXT7"
   },
   "outputs": [],
   "source": [
    "'''import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM with url\n",
    "model_without_url_wo_sw_removal = torch.load(\n",
    "    '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_without_url_without_sw_removal.pt')\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded)).to(device)\n",
    "outputs = model_without_url_wo_sw_removal(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEo1BNlyGWTI"
   },
   "outputs": [],
   "source": [
    "'''import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as sw\n",
    "stop_words = sw.words('english')\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def remove_number(x):\n",
    "    x =  re.sub(r'[0-9]+', '', x)\n",
    "    return x\n",
    "def remove_punctuation_re(x):\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    return x\n",
    "def pre_process_3(input_list):\n",
    "    # Converting to lower case\n",
    "    lower = [s.lower() for s in input_list]\n",
    "    # Removing number \n",
    "    remove_num = [remove_number(s) for s in lower]\n",
    "    # Removing punctuation\n",
    "    remove_pun = [remove_punctuation_re(s) for s in remove_num]\n",
    "    # Tokenization \n",
    "    Tokenized = [word_tokenize(s) for s in remove_pun]\n",
    "    # Removing stop words\n",
    "    #for tokens in Tokenized:\n",
    "    #    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "    #    remove_sw.append(filtered_sentence)\n",
    "    # Stemming\n",
    "    result = []\n",
    "    for tokens in Tokenized:\n",
    "        stemmed = [stemmer.stem(s) for s in tokens]\n",
    "        result.append(stemmed)\n",
    "    # Lemmatization\n",
    "    #result = []\n",
    "    #for tokens in result_1:\n",
    "    #    lemma_sentence = [lemmatizer.lemmatize(w) for w in tokens ]\n",
    "    #    result.append(lemma_sentence)\n",
    "    return result\n",
    "\n",
    "training_posts_no_url_no_sw_processed = pre_process_3(training_posts_no_url)\n",
    "testing_posts_no_url_no_sw_processed = pre_process_3(testing_posts_no_url)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6uT8GqFH9Og"
   },
   "outputs": [],
   "source": [
    "'''emb_list = []\n",
    "for i in training_posts_no_url_no_sw_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_no_url_no_sw_processed:\n",
    "    emb_list.append(j)\n",
    "print(len(emb_list))\n",
    "from gensim.models import FastText\n",
    "word_emb_model_1_with_url = FastText(emb_list, size=200, window=5, min_count=0, workers=-1, sg=1)\n",
    "\n",
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "\n",
    "word_list = list(word_set) \n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1\n",
    "\n",
    "import numpy as np\n",
    "emb_dim = word_emb_model_1_with_url.vector_size + word_emb_model_2.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if word in word_emb_model_1_with_url and word in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], word_emb_model_2[word]),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate((word_emb_model_1_with_url[word], [0]*word_emb_model_2.vector_size),0))\n",
    "    elif word in word_emb_model_1_with_url and word not in word_emb_model_2:\n",
    "        emb_table.append(np.concatenate(([0]*word_emb_model_1_with_url.vector_size, word_emb_model_2[word]),0))\n",
    "    else:\n",
    "        emb_table.append([0]*emb_dim)\n",
    "emb_table = np.array(emb_table)\n",
    "\n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded\n",
    "\n",
    "train_pad_encoded = encode_and_add_padding(training_posts_no_url_no_sw_processed, seq_length, word_index )\n",
    "test_pad_encoded = encode_and_add_padding(testing_posts_no_url_no_sw_processed, seq_length, word_index )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHZC5x0rISto"
   },
   "outputs": [],
   "source": [
    "'''unique_labels = np.unique(training_labels)\n",
    "lEnc = LabelEncoder()\n",
    "training_labels_encoded = lEnc.fit_transform(training_labels)\n",
    "testing_labels_encoded = lEnc.transform(testing_labels)\n",
    "n_class = len(unique_labels)\n",
    "print(unique_labels)\n",
    "print(lEnc.transform(unique_labels))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pm-xMbPrIdWX"
   },
   "outputs": [],
   "source": [
    "'''print(type(train_pad_encoded))\n",
    "import torch\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "\n",
    "\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model, '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_without_url_without_sw_removal_without_lemma.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aFmME9OIpP1"
   },
   "outputs": [],
   "source": [
    "'''import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM with url\n",
    "model_without_url_wo_sw_removal = torch.load(\n",
    "    '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_without_url_without_sw_removal_without_lemma.pt')\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded)).to(device)\n",
    "outputs = model_without_url_wo_sw_removal(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e4pvhwlBgE-",
    "outputId": "6026d329-1351-41e6-ce0c-487352b22134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Evaluation with different Data Pre-processing Techniques (w/wo URL)\n",
      "+---------------------+-----------------------------+\n",
      "| Model               |   Weighted Average F1-Score |\n",
      "+=====================+=============================+\n",
      "| Bi-LSTM with URL    |                        0.55 |\n",
      "+---------------------+-----------------------------+\n",
      "| Bi-LSTM without URL |                        0.57 |\n",
      "+---------------------+-----------------------------+\n",
      "Please note that for evaluating performance with/withour URL, all other pre-process techniques were kept identical\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Performance Evaluation with different Data Pre-processing Techniques (w/wo Lemmatization)\n",
      "+-------------------------------+-----------------------------+\n",
      "| Model                         |   Weighted Average F1-Score |\n",
      "+===============================+=============================+\n",
      "| Bi-LSTM with Lemmatization    |                        0.54 |\n",
      "+-------------------------------+-----------------------------+\n",
      "| Bi-LSTM without Lemmatization |                        0.55 |\n",
      "+-------------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Performance Evaluation with different Data Pre-processing Techniques (w/wo URL)\")\n",
    "mydata = [\n",
    "          [\"Bi-LSTM with URL\", 0.55\n",
    "           ],\n",
    "          [\"Bi-LSTM without URL\", 0.57\n",
    "           ]  \n",
    "]\n",
    "head = [\"Model\", \"Weighted Average F1-Score\"]\n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))\n",
    "print(\"Please note that for evaluating performance with/withour URL, all other pre-process techniques were kept identical\")\n",
    "print(\"\")\n",
    "print(\"==\" * 40)\n",
    "print(\"\")\n",
    "print(\"Performance Evaluation with different Data Pre-processing Techniques (w/wo Lemmatization)\")\n",
    "mydata_2 = [\n",
    "          [\"Bi-LSTM with Lemmatization\", 0.54\n",
    "           ],\n",
    "          [\"Bi-LSTM without Lemmatization\", 0.55\n",
    "           ]  \n",
    "]\n",
    "head = [\"Model\", \"Weighted Average F1-Score\"]\n",
    "# display table\n",
    "print(tabulate(mydata_2, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKwV4wt6kN7Z"
   },
   "source": [
    "As shown in the above table, with other pre-processing techniques remaining unchanged, removing URLs from the input data would improve the model performance. While keeping all pre-processing techniques unchanged, using lemmatization to pre-process the data would surprisingly lower the model performance. <br>\n",
    "URLs are links to a webpage, and the URLs are usually long, yet they mostly do not contain any helpful information. Moreover, most URLs contain random combinations of numbers and letters, which have no physical meanings. Therefore, removing URLs would not lose much valuable information and will likely improve the model performance since some useless noises (random combinations of letters and numbers in URLs) are removed at the same time .<br>\n",
    "Lemmatization was a method that converts a given word back to its original state. For example, after lemmatization, the word \"is\" or the word \"are\" would be output as \"be\" which was their original state. However, the above table shows that the model trained with not lemmatized input data had slightly better performance. The reason for that might be the poorly designed pre-processing stage. A lemmatization stage follows the stemming stage. Stemming and lemmatization are two very similar pre-processing techniques. This means that there is no significant difference between the data going through only the stemming stage and the data going through both stemming and lemmatization. And that would lead to the trained model having similar performance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gwVpllNoOiY"
   },
   "source": [
    "## 4.3. Performance Evaluation with Different Input\n",
    "\n",
    "\n",
    "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
    "Note that it will not be marked if you do not display it in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWS3oonaoOiY"
   },
   "source": [
    "(*Please show your empirical evidence and justification*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mREYoAaq9TP3"
   },
   "outputs": [],
   "source": [
    "print(len(training_posts_no_url_processed))\n",
    "print(len(testing_posts_no_url_processed))\n",
    "emb_list = []\n",
    "for i in training_posts_no_url_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_no_url_processed:\n",
    "    emb_list.append(j)\n",
    "print(len(emb_list))\n",
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xUKinqC9uyI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 1 embedding model\n",
    "def concat_1_model(word_emb_model_1):\n",
    "    emb_dim = word_emb_model_1.vector_size\n",
    "    emb_table = []\n",
    "    for i, word in enumerate(word_list):\n",
    "        if word in word_emb_model_1:\n",
    "            emb_table.append(word_emb_model_1[word])\n",
    "        else:\n",
    "            emb_table.append([0]*emb_dim)\n",
    "    emb_table = np.array(emb_table)\n",
    "    return emb_table, emb_dim\n",
    "# 2 embedding models\n",
    "def concat(word_emb_model_1, word_emb_model_2):\n",
    "    emb_dim = word_emb_model_1.vector_size + word_emb_model_2.vector_size\n",
    "    emb_table = []\n",
    "    for i, word in enumerate(word_list):\n",
    "        if word in word_emb_model_1 and word in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate((word_emb_model_1[word], word_emb_model_2[word]),0))\n",
    "        elif word in word_emb_model_1 and word not in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate((word_emb_model_1[word], [0]*word_emb_model_2.vector_size),0))\n",
    "        elif word in word_emb_model_1 and word not in word_emb_model_2:\n",
    "            emb_table.append(np.concatenate(([0]*word_emb_model_1.vector_size, word_emb_model_2[word]),0))\n",
    "        else:\n",
    "            emb_table.append([0]*emb_dim)\n",
    "    emb_table = np.array(emb_table)\n",
    "    return emb_table, emb_dim\n",
    "\n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTqc1XdioOiZ"
   },
   "outputs": [],
   "source": [
    "# Trining model W2V Skip Gram\n",
    "from gensim.models import Word2Vec\n",
    "word_emb_model_ft_sg = Word2Vec(emb_list, size=200, window=5, min_count=0, workers=-1, sg=1)\n",
    "# Training model W2V CBOW\n",
    "word_emb_model_ft_cbow = Word2Vec(emb_list, size=200, window=5, min_count=0, workers=-1, sg=0)\n",
    "# Pretraind 1 \"glove-wiki-gigaword-100\"\n",
    "import gensim.downloader as api\n",
    "word_emb_model_pre_1 = api.load(\"glove-wiki-gigaword-100\")\n",
    "# Pretrained 2 \"glove-twitter-100\"\n",
    "word_emb_model_pre_2 = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cogCMopc8k9Q"
   },
   "outputs": [],
   "source": [
    "train_pad_encoded_no_url = encode_and_add_padding(training_posts_no_url_processed, seq_length, word_index )\n",
    "test_pad_encoded_no_url = encode_and_add_padding(testing_posts_no_url_processed, seq_length, word_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_K71n57ApJX"
   },
   "outputs": [],
   "source": [
    "# W2V SG\n",
    "emb_table, emb_dim = concat_1_model(word_emb_model_ft_sg)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/bi_LSTM_w2v_sg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UymiId1flViA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    '/content/bi_LSTM_w2v_sg.pt'\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"W2V SG\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyUKLbtxC7d0"
   },
   "outputs": [],
   "source": [
    "'''# W2V CBOW\n",
    "emb_table, emb_dim = concat_1_model(word_emb_model_ft_cbow)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_w2v_cbow.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNsPWgwnDt-H"
   },
   "outputs": [],
   "source": [
    "'''# Pretraind 1 \"glove-wiki-gigaword-100\"\n",
    "emb_table, emb_dim = concat_1_model(word_emb_model_pre_1)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_wiki.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9q6pRlfEHGy"
   },
   "outputs": [],
   "source": [
    "'''# Pretrained 2 \"glove-twitter-100\"\n",
    "emb_table, emb_dim = concat_1_model(word_emb_model_pre_2)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_twitter.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klChDpdjLRVC"
   },
   "outputs": [],
   "source": [
    "'''# W2V SG + wiki\n",
    "emb_table, emb_dim = concat(word_emb_model_ft_sg, word_emb_model_pre_1)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_sg+wiki.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NikfZnLoLxWN"
   },
   "outputs": [],
   "source": [
    "'''# W2V SG + twi\n",
    "emb_table, emb_dim = concat(word_emb_model_ft_sg, word_emb_model_pre_2)\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.01\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "for epoch in range(total_epoch):      \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_torch) \n",
    "    loss = criterion(outputs, target_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_sg+twi.pt')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGWIXPpDBCtA"
   },
   "outputs": [],
   "source": [
    "'''# W2V SG\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_w2v_sg.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"W2V SG\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))\n",
    "# W2V CBOW\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_w2v_cbow.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"W2V CBOW\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))\n",
    "# Pretrain wiki\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_w2v_cbow.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Pretrain WIKI\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))\n",
    "# Pretrain twitter\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_twitter.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Pretrain TWI\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))\n",
    "# W2V SG + wiki\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_sg+wiki.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"W2V SG + WIKI\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))\n",
    "# W2V SG + twi\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/5046 assignment 1/bi_LSTM_sg+twi.pt\"\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"W2V SG + TWI\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6OUEFksOT1-",
    "outputId": "c7790e9a-7db5-4141-bb99-ae90eb582830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Evaluation with different input\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Model                                        |   Weighted Average F1-Score |\n",
      "+==============================================+=============================+\n",
      "| Word2Vec Skip-Gram                           |                        0.43 |\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Word2Vec CBOW                                |                        0.5  |\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Pretrianed glove-wiki-gigaword-100           |                        0.5  |\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Pretrianed glove-twitter-100                 |                        0.61 |\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Word2Vec Skip-Gram + glove-wiki-gigaword-100 |                        0.57 |\n",
      "+----------------------------------------------+-----------------------------+\n",
      "| Word2Vec Skip-Gram + glove-twitter-100       |                        0.59 |\n",
      "+----------------------------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Performance Evaluation with different input\")\n",
    "mydata = [\n",
    "          [\"Word2Vec Skip-Gram\", 0.43\n",
    "           ],\n",
    "          [\"Word2Vec CBOW\", 0.50\n",
    "           ],\n",
    "          [\"Pretrianed glove-wiki-gigaword-100\", 0.50\n",
    "           ],\n",
    "          [\"Pretrianed glove-twitter-100\", 0.61\n",
    "           ],\n",
    "          [\"Word2Vec Skip-Gram + glove-wiki-gigaword-100\", 0.57\n",
    "           ],\n",
    "          [\"Word2Vec Skip-Gram + glove-twitter-100\", 0.59\n",
    "           ],\n",
    "]\n",
    "head = [\"Model\", \"Weighted Average F1-Score\"]\n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z88DNrsOt8_w"
   },
   "source": [
    "The above table shows that the best-performing model was trained with only glove-twitter word embeddings. The lowest was trained using the w2v skip-gram embedding model. <br>\n",
    "By comparing the input with skip-gram and the CBOW word embeddings, the model trained with only CBOW had better performance. According to Mikolov and his team, CBOW could better represent frequently appearing words (Mikolov et al., 2013). Therefore, one explanation for this might be that in the training set, many words had frequently appeared throughout the data set, causing the CBOW model to out-perform the SG model. <br>\n",
    "By comparing the concatenation input and the single-embedding input, it was apparent that using concatenation input would be better than using a MBTI-trained w2v input. The reason for this would be the size of the data set. Most likely, the pre-trained models were trained on large size corpus, leading the word embedding models to be more accurate. On the other hand, by comparing the concatenation input and the single pre-trained input, the single pre-trained input out-performed the concatenation word embedding input. This might be because the low accuracy of MBTI-trained embedding essentially worsened the performance. \n",
    "<br>\n",
    "The Twitter-pre-trained model had the best performance might be that the text in the MBTI data set was more oral oriented, meaning that the text was less formal, which was closer to text on Twitter than text on Wiki. Therefore, the model trained with the Twitter-pre-trained model achieved the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vg08uf3hpyoF"
   },
   "source": [
    "## 4.4. Performance Evaluation with Different Sequence Models\n",
    "\n",
    "\n",
    "You are required to evaluate with the testing dataset and provide the table with f1 of test set.\n",
    "Note that it will not be marked if you do not display it in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e_nVbdrpyoK"
   },
   "source": [
    "(*Please show your empirical evidence and justification*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KT6EfkKRHJ9X"
   },
   "outputs": [],
   "source": [
    "embedded_docs_train = []\n",
    "maxlength = 100\n",
    "for doc in training_posts_no_url_processed:\n",
    "    embedded_doc = []\n",
    "    for i in range(maxlength):\n",
    "        if i == len(doc):\n",
    "            for j in range(maxlength-i):\n",
    "                embedded_doc.append([0]*100)\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                embedded_doc.append(word_emb_model_2.wv[doc[i]])\n",
    "            except:\n",
    "                embedded_doc.append([0]*100)\n",
    "    embedded_docs_train.append(embedded_doc)\n",
    "\n",
    "embedded_docs_test = []\n",
    "maxlength = 100\n",
    "for doc in testing_posts_no_url_processed:\n",
    "    embedded_doc = []\n",
    "    for i in range(maxlength):\n",
    "        if i == len(doc):\n",
    "            for j in range(maxlength-i):\n",
    "                embedded_doc.append([0]*100)\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                embedded_doc.append(word_emb_model_2.wv[doc[i]])\n",
    "            except:\n",
    "                embedded_doc.append([0]*100)\n",
    "    embedded_docs_test.append(embedded_doc)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKAr72_fIDsQ"
   },
   "outputs": [],
   "source": [
    "embedded_docs_train = np.array(embedded_docs_train)\n",
    "print(embedded_docs_train.shape)\n",
    "embedded_docs_test = np.array(embedded_docs_test)\n",
    "print(embedded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLw_NP3OI8C1"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Bi_RNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bi_RNN_Model, self).__init__()\n",
    "        # set the bidirectional to True\n",
    "        self.rnn = nn.RNN(n_input, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*n_hidden,n_class)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x, h_n = self.rnn(x)\n",
    "        # concat the last hidden state from two direction\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        output = self.linear(hidden_out)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSUWojM4JCrw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "#training_labels_encoded = lEnc.fit_transform(training_labels)\n",
    "#testing_labels_encoded = lEnc.transform(testing_labels)\n",
    "\n",
    "seq_length = embedded_docs_train.shape[1]\n",
    "n_input = embedded_docs_train.shape[2]\n",
    "n_class = np.unique(training_labels_encoded).shape[0]\n",
    "\n",
    "# Set the hyperparameters \n",
    "n_hidden = 50\n",
    "batch_size = 256\n",
    "total_epoch = 100\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HVIY_47J-l5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Initialize model, set up the loss calculator and optimizer\n",
    "model = Bi_RNN_Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(total_epoch):\n",
    "    train_loss = 0\n",
    "    for ind in range(0,embedded_docs_train.shape[0],batch_size):\n",
    "        input_batch = embedded_docs_train[ind:min(ind+batch_size, embedded_docs_train.shape[0])]\n",
    "        target_batch = training_labels_encoded[ind:min(ind+batch_size, embedded_docs_train.shape[0])]\n",
    "        input_batch_torch = torch.from_numpy(input_batch).float().to(device)\n",
    "        target_batch_torch = torch.from_numpy(target_batch).view(-1).to(device)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_batch_torch) \n",
    "        loss = criterion(outputs, target_batch_torch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%10 == 9:\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        acc= accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
    "        print('Epoch: %d, loss: %.5f, train_acc: %.2f' %(epoch + 1, loss.item(), acc))\n",
    "print('Finished Training')\n",
    "torch.save(model, \n",
    "           '/content/bi_RNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9UZMtmzkXnK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "     '/content/bi_LSTM.pt'\n",
    "    )\n",
    "input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "outputs = model_without_url(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"bi-LSTM\")\n",
    "print(classification_report(testing_labels_encoded,predicted.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7D9s0JSkj4mO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model bi-LSTM without url\n",
    "model_without_url= torch.load(\n",
    "     '/content/bi_RNN.pt'\n",
    "    )\n",
    "model_without_url.eval()\n",
    "outputs = model_without_url(torch.from_numpy(embedded_docs_test).float().to(device)) \n",
    "predicted = torch.argmax(outputs, 1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"bi-RNN\")\n",
    "print(classification_report(testing_labels_encoded, predicted.cpu().numpy(),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrqyG--9QFI5",
    "outputId": "559710a1-68d7-4c1f-fc54-e8f9db02a9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Evaluation with different sequence models\n",
      "+---------+-----------------------------+\n",
      "| Model   |   Weighted Average F1-Score |\n",
      "+=========+=============================+\n",
      "| bi-LSTM |                        0.62 |\n",
      "+---------+-----------------------------+\n",
      "| bi- RNN |                        0.49 |\n",
      "+---------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Performance Evaluation with different sequence models\")\n",
    "mydata = [\n",
    "          [\"bi-LSTM\", 0.62\n",
    "           ],\n",
    "          [\"bi- RNN\", 0.49\n",
    "           ]\n",
    "]\n",
    "head = [\"Model\", \"Weighted Average F1-Score\"]\n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_yzm1lfJMNA"
   },
   "source": [
    "By comparing the model between LSTM and RNN, it was evident that the LSTM model had a significantly better performance than the RNN model.<br>\n",
    "In terms of RNN, one of its drawbacks is that RNN is not capable of handling long-term dependencies, such that it can only consider hidden states from its previous cell. To solve this problem, LSTM was invented. LSTM is a variant of RNN, for which LSTM is designed to store information over extended time intervals with backpropagation (Hochreiter & Schmidhuber, 1997). With that being said, LSTM can store information\n",
    " much longer than comparing to RNN. Therefore, in this section, when training with relatively long sentences, LSTM was able to take many words into account. In contrast, RNN can only take its previous word into account, leading to the LSTM model outperforming the RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P28Z1k36MZuo"
   },
   "source": [
    "## 4.5. HyperParameter Testing\n",
    "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.* Note that it will not be marked if you do not display it in the ipynb file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYzrA_s2tTaz"
   },
   "source": [
    "(*Please show your empirical evidence and justification*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTLyQEeZMZ2f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "learning = [0.1, 0.01, 0.001]\n",
    "result = []\n",
    "for i in learning:\n",
    "    epoch = [1, 5,  10, 50, 100, 200, 500]\n",
    "    epoch_f1 = []\n",
    "    for j in epoch:\n",
    "        print(\"Training with epoch {} and learning rate {}\".format(j, i))\n",
    "        vocab_size = len(word_list)\n",
    "        total_epoch = j\n",
    "        learning_rate = i\n",
    "\n",
    "        model = Model().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        input_torch = torch.from_numpy(np.array(train_pad_encoded_no_url)).to(device)\n",
    "        target_torch = torch.from_numpy(np.array(training_labels_encoded)).view(-1).to(device)\n",
    "\n",
    "        for epoch in range(total_epoch):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_torch) \n",
    "            loss = criterion(outputs, target_torch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Finished Training')\n",
    "        input_torch = torch.from_numpy(np.array(test_pad_encoded_no_url)).to(device)\n",
    "        outputs = model(input_torch) \n",
    "        predicted = torch.argmax(outputs, -1)\n",
    "        from sklearn.metrics import f1_score\n",
    "        f1 = f1_score(testing_labels_encoded,predicted.cpu().numpy(), average='weighted')\n",
    "        print(f1)\n",
    "        epoch_f1.append(f1)\n",
    "    result.append(epoch_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "8hDQ4NzRX86N",
    "outputId": "6b4809b8-cc99-4f72-87ab-d38130a345ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "xpoints = np.array([1, 5,  10, 50, 100, 200, 500])\n",
    "plt.plot(xpoints, result[0], color = 'green', label = \"Overall\", marker = \"o\")\n",
    "plt.title(\"Weighted f1-score vs Epoch with learning rate of {}\".format(learning[0]))\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Wighted f1-score') \n",
    "plt.show()\n",
    "\n",
    "xpoints = np.array([1, 5,  10, 50, 100, 200, 500])\n",
    "plt.plot(xpoints, result[1], color = 'green', label = \"Overall\", marker = \"o\")\n",
    "plt.title(\"Weighted f1-score vs Epoch with learning rate of {}\".format(learning[1]))\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Wighted f1-score') \n",
    "plt.show()\n",
    "\n",
    "xpoints = np.array([1, 5,  10, 50, 100, 200, 500])\n",
    "plt.plot(xpoints, result[2], color = 'green', label = \"Overall\", marker = \"o\")\n",
    "plt.title(\"Weighted f1-score vs Epoch with learning rate of {}\".format(learning[2]))\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Wighted f1-score') \n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-OCggPHaewI"
   },
   "source": [
    "As shown in the plots above, it was obvious that the model would be in its peak performance when using 100 epochs to train the model. The final learning rate adopted for sections 1 through 3 was 0.001.<br>\n",
    "The reason for choosing 100 epochs was that 100 was the optimal number that the trained model was not overfitting and had the best performance. With more epochs, the model might overfit, which would lead to worse performance and might take longer to train. <br>\n",
    "The reason for choosing 0.001 as the learning rate was that when learning rates were 0.1 and 0.01, the performance did improve faster with a larger amount of epochs (steeper slope). However, when using a small number of epochs, the models v overshot the minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIfa2nm85H9I"
   },
   "source": [
    "#5 - Test your model via Colab Form Fields User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrCqpwHD5RG1"
   },
   "source": [
    "You are required to design a user interface so that user can input a textual sentence via the colab form fields user interface to get the personality type classification result from your trained model. *You can just modify based on the following Colab Form Fields template*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HO_aV5bz5-ry",
    "outputId": "eb635c41-9f48-4f15-bdde-b3ba49a39a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'Actually, from these results, it looks like you're triple-withdrawn: 5w4, 9w8, 4w5.  It would appear that you just happen to have strong 2, 6, and 7 traits.|||It's odd that you're associating the whole heart triad with narcissism.  Also, I would associate Fives with having some antisocial disorder, not Eights (BTW let's set aside the aspergers and call it...|||So is my mom.  It sometimes annoys me to pieces:  My mom: Go do *insert known, to-do task here* Me: I know My mom: Well, if you know, then why don't you go do it?  ...yeah, I'm not one...|||I'm gonna guess the EJ types are most likely to groupthink, but I'm not entirely sure.  Thoughts?  Also, which types are least likely to groupthink?|||Very true.  My guess is that 9s are the most idealized type (thanks to our high levels of neutrality and inner tranquility), but from the perspective of a 9, it isn't worth it to idealize any type. ...|||I hardly ever wear hats, if at all.  Nice new avatar BTW, dealwithit.|||The ENTJ I'm currently living with apparently has used his Se via cooking, amid other things I'm not 100% sure of.  He's quite nice with Se, compared to Te-Ni alone.  Sometimes I kinda wonder how...|||You have been criticized of having less thanks than posts /guilty|||*A Type 9 looks at the poll...*  We're so popular :proud:  *Goes and votes for 9*  EDIT... and 9th vote!  What a number :crazy:|||It seems both of the ISPs seem to hold out relationships and get married longer than the ESPs.  Also, some stats from Personality Page:  Highest Percentage Married   (From highest to...|||*Looks back at thread*  Riiiiiiiiiight, so why did I create this thread? :dry:  (maybe too much like comparing an ISTP to an INTP?)|||Maybe an INTP in a Ti-Si loop?  I tend to be nit-picky about my environment as well due to my high Si.|||So am I, and although my 5w6 is close, I'm a 9w1 (I have absolutely no 8 anywhere in my Enneagram type at all).|||Not to mention it feels somewhat disturbing and unreal to do it all the time.|||PSTypes Enneagram Test Results  The Distribution of Your Scores    Type One:  15  Type Two:|||I'm probably the one all the way to the right.   Am I now weird for looking well? :crazy:|||Maybe because Enneagram isn't as official and popular as MBTI, and so it's hard to find broad real-world stats.|||TP and FP aren't necessarily associated with a Pe function.  They're associated with dom/aux Ti and Fi respectively.  Anyway, you could divide up the 16 types in a number of ways of four: EJ, EP,...|||Not an SJ, but my mom, who is an SJ, her parents are most likely ESFJ and ISTP.|||Why?  The discussion's fine  nothing's heated up in here.|||I used to wear a watch when I was younger, but watches tend to irritate my wrist, so I stopped.  Besides, there are other ways for me to tell time when it's necessary.  Also, beware: under...|||1. Words of Affirmation  Meh.  2. Gifts  Giving them: yep.  Receiving them is another story.  3. Acts of Service|||1: Not entirely sure.  They're mostly about places than anything else.  Seldom, if at all, are there people in my dreams. 2: Often, like most other things, I remember a dream quite vividly, but the...|||They'll probably get along quite well.  This is probably true for any XwY with a YwX.  BTW if you were wondering, the little w between the numbers stands for wing, not with (it can be unclear...|||I've wondered how common each of the 9 fundamental Enneagram types are.  Does anyone know or have a link?|||From typelogic.com:  Intuition is tertiary--as the ESFJ matures, and as situations arise which call for suspension of criticism, Ne is allowed to play.  Under the leadership of the Fe function,...|||From typelogic.com:  As the ESTJ matures, and as situations arise which call for suspension of criticism, Extraverted iNtuition is allowed to play.  Under the leadership of the Te function,...|||Again, sorry if I am harsh.  Try not to take everything here personally.  If you look inside the parentheses, there's my alternate possibility (I'm not inconsiderate!).  It turns out I was just...|||I tend to apologize like that too: very reasoned out.  Maybe it's a T/F thing.|||This obligation of SJs (not just ESTJs), amid others, is what drives me up a wall sometimes.  My ESFJ mother has this tendency to do this to me (although not to the degree you're encountering).  ...|||I find this interesting.  I never would've guessed that an ESTJ would tell a white lie (this in part due to my stereotypical views of ESTJs).  As a thinking type, I might get thrown off by this, and...|||Not to be harsh, but speaking of lies, you could be lying about your strong STJ.  It looks like you're just strong J (either that or I could be misreading the scale).  So, another question: what...|||Here's a third ISTP to add to that.  I will say, though, that because of my autism, I have an unusually strong Si.  It could happen to an ISFP, and the result could be an autistic ISFP with ISFJ...|||Here, I replied to your thread, happy? :crazy:  Anyway, I once read that IFPs such as you don't seem to have much patience with types whose preferences are strongly T or J (let alone TJ).|||Mostly Se and Ni.  I rule with Ti, so I don't need work there.  Te and Fi are doing OK, and they will develop better in my later life.  Ne I just suck at, and Fe I'm not too good with either.  Both...|||P. S.  Why do you terms and conditions have to be so long?????  Do you have any idea how discouraging and redundant that is?  Ever heard of plain English and not legalese?|||I need to get out more /recurringthoughtofmine|||Sounds like you need to relax!  It also sounds like you need to forgive your INTP's detached, perceiving nature.  Maybe he got quickly bored!|||Thanks to everyone here who shared their two-sided Se understanding.  I remember my high school ENFJ teacher taking us outside during homeroom.  Se relief :proud:|||First impression: ESTJ (maybe with a strong Se?)  Certainly underdeveloped in terms of cognitive functions, such as Ne and Fi.|||It looks like you have just won out the rest of us... either that or you weren't being true to yourself.|||ISTJ: Cup of coffee ESTJ: Judge's mallet (for lack of a proper name, if there is one) ISTP: Someone fixing up their cool vehicle (be it a car, motorcycle, bicycle, or otherwise) ISFP: An artist...|||The question is, will it be because we humans could control ourselves, or because mother nature forced us?|||I would guess this is an Si thing...    Given my strong Si, I have become like this as well.  However, being an SP, I don't need routine, just need to know how it works.|||I find it fascinating that some ISFJs have higher Te than Ti.  It had me wondering if most other SJs have higher Te and Fe than their Ti and Fi.  When my ESFJ mother tested out, she had higher Te...|||How nostalgic are you?  It would appear that Si nostalgia is fairly strong among you ESFJs, being Si-aux.|||I wondered where this thread went...  *has a thought of music and therefore cannot be described*|||From an ISTP with aux. Se, this is an insightful thread.  I've sometimes wondered if ENFJs (or ENxJs for that matter) experience Se in a here-and-now manner like SPs do.|||I can imagine, like any identity relationship, that it'll be a nice one, but eventually will get boring.  I sometimes wonder what an ISFP-ISTP relationship would look like.|||Let's see...  Playing games (especially ones that integrate the Ti element, which few adventurous games seem to do), skiing, biking, hiking, climbing, procrastinating here (not uncommon among us...'\", \"' does, indeed, help. To answer the question, my IQ is 129, and it was professionally administered. But, it doesn't mean anything to me--I don't need a number to tell me I'm intelligent, I...|||Shall I play you a song on the world's smallest violin?|||I really don't get how you guys think she's an introvert. She's said many times about how extroverted she is, and she was voted Most Talkative by her high school. I can see an introvert being...|||Assuming morality is absolute, can you explain to me the absolute best moral choice out of every situation? I'm assuming you cannot, and on who's authority should we accept these truths? It cannot be...|||Hello all,  I originally joined this site in late 2009, and I lurked for many months before. I had just turned 19 and started college , in search of myself, and I used this forum to help discover...|||1. Log in after a week or so of not being on here. 2. Look at INFJ forum, sees that all the new threads are already ones that I've seen and discussed in the past. 3. Check the new posts in case I...|||I hope everyone realizes the difference between a nice guy and a, well, nice guy.|||www.youtube.com/watch?v=DOX9l4Ys7NY|||I would retire my account since I don't ever come on here anymore (and I don't really care about MBTI anymore), but why put an unnecessary restriction on myself?|||I'm not a virgin. In some ways, I still wish I was--I lost my virginity to someone who I wasn't in love with. The girl I'm with right now is, and if it weren't for that one girl, I would be too and...|||I'm 21. I'm young, amirite?|||Having the feeling of being alone.  Being able to tell a lot about a person just by their energy. It's almost like I've known them for years. And then, if they find this out, it freaks them out....||| think it might be more of a biological thing and how you were raised more than how it is based on your type, but I can see how type could play a part.  As for me....yeah, I'm nowhere near an...|||I suppose I still am, but I've lowered my standards so much to where I date people I don't even like, probably just to not feel alone. I'm a little disgusted with myself at the moment.||| know what you mean. I've had this same problem for the longest time, and I too can seem to spark relationships better over text. Weird. But, anyways, I've just forced myself to be a little more...|||I can imagine most INFJs can relate to this.    trust test results. That being said, I could very well be an INFJ type 3.|||My views have always been that I will never have sex with someone that I know is just gonna lead to sex and that's it. Up to this point, I've followed through to that, because I can't imagine giving...|||For me, like most of you, it comes out very early on, but I try to control my tongue for as long as I can, so I hardly ever say it at all, at least intentionally. At the beginning, I think, it's less...|||Right now I'm debating whether I'm an ENTP or INFJ.  Sounds very strange, but both of them fit me.|||Who doesn't get a little genocidal every now and then?|||Walter may actually be an INFJ, not an INTJ. The reason I say this is that it's VERY clear to me that Gus is an INTJ, but there seems to be some variance between them. I'll be able to explain more...|||Bout damn time!|||I'm a dude, so it's kind of embarrassing that I like this show, but it ain't too bad. The only two I know are Lorelai and Rory, and they're ESFP and INFJ/ISFJ, respectively.|||   would say you're an ESFP or ENFP, probably leaning stronger with ESFP over ENFP.  You're not introverted. At all.|||Are you seriously basing your dating life based on some Personality Theory that may or may not be bullshit?|||I seriously hope this is a joke thread. It's getting that bad that I can't tell if someone is trolling, or just flat out fucking stupid.  As for who's going to win--unless Romeny wins the...|||Congratulations??|||I never made one in the first place, so.....hey?  I'm not sure why I'm even making this, as I'm probably just gonna retire this account soon anyway, but, ya know, just thought I'd make one.|||You're typism.  Honestly, I don't really have a specific type that annoys me. Stupid annoys me, not type.  That being said, for the love of FSM and all that is holy, I am NEVER, EVER, EVER...||| this isn't the first time you've posted something like this in the two years I've been here, it's in all likelihood depression, dude. I had the same symptoms for, oh, 7 years or so, and when I...|||I'm my own partner.|||EDIT I guess that's what I get for not reading the whole post.|||Can I come tuck you in?|||You're probably a 3, then.  I'm a type three myself, and I fall into the more reserved category with most people. I would still consider myself extroverted, but people who talk nonstop actually get...||| common. I'm a 3, but a 3w4, not a 3w2.|||Not at all ENTP. I'd say ISTP, or ESTP if that doesn't work.||| the words right out of my mouth.|||Just so everyone's clear, getting a percentage on a MBTI doesn't mean you're 75% introvert. It means you can be pretty confident you're an introvert.  Back on topic, I'm pretty much certain that...|||Yeah, same thing happened to me. Fuckers.  Dear stupid people--just because I don't show it doesn't mean I'm not judging you. At least you keep me entertained.  Excuse my misogyny, but fuck...|||Tell me about it. But, ironically, I'm dating a girl from California who moved over here a while ago, and I met her through Ok Cupid. Didn't actually expect that thing to produce results, but it has!...|||I'd say Obama is most definitely an ENFJ. Speaking to common values, but sticking to his own internal vision, etc.  Sarah Palin--ESFJ  Ronald Reagan--Hard to tell. Probably ESTP in my opnion. ...'\", \"'As an ENFJ, how ambitious are you? I am fairly ambitious. I have two undergrad degrees; Sociology/Religious Studies & in Education in ESL/Secondary Education. I left about a 3 year gap between both...|||Welcome!  I find that writing my thoughts in free-flow about the situation helps me cope with separating my feelings with the other person. I also remind myself that I will not allow another...|||healthy ways - workout regularly, yoga, talk to my boyfriend/friends. Maintain a regular sleep schedule.  unhealthy - chocolate. more chocolate. Sometimes other unhealthy foods :/|||It is going excellent! Are relationship is building an amazing foundation. We love to express our feelings for each other through poetry (my preference), through drawings & art (his preference). We...|||Hey INFPs - barely post anymore. I just wanted to share that I met my INFP boyfriend on Feb. 4th of this year. We met through a dating app. We have never been more in love - we've both described our...|||It's been six dates and I found myself an INFP [he took the test ... and yes, he is an INFP]. The connection is just so amazing and intense right now, it even scares me.  He told me he has never...|||I am curious what you'd like. Yeah, we ENFJs are unique. Wonder if this has to do with enneagram/love styles.|||I don't have a ton of info. as I have not met this guy in person & only chatted with him yesterday for the first time online. Here's what I do know:  -according to his profile he is looking for...|||Here are some signs:  -they tend to talk faster  -they will have a tougher time filling in gaps in the conversation -sometimes they won't initiate the interaction, get a bit more shy or wait till...|||Dislike my INFP best-friend's sister. We only just met this month. I don't know I felt strangely upset about why I don't like her sister and guilty. The girl is so self-absorbed & does things that...|||Yeah. I hear you there. You just never know that you will fall in love with someone. It does come out of nowhere.|||Well put. I am borrowing this one in the future.|||Here are some ideas: -anything handwritten or created by hand (so original) this can range from poetry, a cleverly created time line of your relationship with photos (in form of a YouTube clip too)...|||I totally relate to what you said there.|||Yes, I am with you. I find it very hard to fall in love. Some people have been known to mistake my friendly, extrovert behaviour as some kind of romantic interest. Must be going out of style to take...|||Thanks for the reply. I agree with what you've said. I would actually like to dump and bail-out on her at this point.|||That is what she said. However, her friend reporting me to HR would not have any affect on me. I don't work there. I am simply an individual who applied for a grant (which is govt money). This money...|||thank you. sane advice.|||Hey, I am working with INFP on a community project. Without going into too many details, a number of people have dropped the ball on her including the Illustrator who was working with her [an INTP]....|||    So good. James is also a Youth Worker/Musician... the non-lyrical version of the song is amazing.. any how..|||  F3  Throwback to 1995.|||Reminds me of the barista at my local Starbucks. Still checking if he is going to do some more rad art work and what's next in his life. lol|||  Bono is rumoured to be an ENFJ as well :)|||yeah, that's the correct way to put. I felt my post was rather unbalanced. The one male ENFP I know is an excellent photographer & very reliable when it comes to delievering his work. I think it was...|||Yes, that's what I was conveying. Glad it made sense :)|||Really :tongue:  I think about the 2 ENFP friends I have (well one isn't a friend anymore by virtue of the total lack of effort she puts in our friendship). They amass so many friends very quickly....|||Is it me, or do other ENFJs have trouble opening up? I find it takes forever for me to actual talk about myself as a person unless someone asks direct questions - but, who the heck does that? :P|||Mostly jealous of their social acumen. They walk into a room & trump all the efforts of other people (namely ENFJs), through their charisma and larger-than-life personalities.  I find they say alot...|||I agree with what Gilly said - point on.   I find that people simply do not directly ask questions about me. I think it is refreshing for ENFJs to be able to talk about themselves. We value...|||1. A big party that will have mostly acquaintances and strangers. There is alcohol, food, and music, but the point is to mainly talk to others.  I would likely be tired thinking about this event,...|||part in bold - Something tells me that you feel disappointed about this or at least confused that he wanted to stay-in-touch, but chooses not to initiate contact. If he isn't choosing to contact you,...|||Thanks for sharing, Gilly.   Well, I believe in my 30's I started to care less about fitting in and pleasing other people's whims, particularly people who wanted me to change. I also became much...|||I didn't read the link yet. I had a best friend that is a ESTJ. Very controlling and unable to accept new ways of doing things. It was her way or the highway. I also felt she cared too much about...|||Thanks for the reply. I like how you helped me work that out, ENFJ brother.|||Have you tried an I feel statement? Basically, you would explain how you feel without implicating him. So, you could say something like, I feel _______________ (frustrated, rejected, shut down...||| yes, good observation. There were other reasons he didn't want to share with me... I often wonder why he would not want to. I typically don't see ESFJs as very private people.   Thanks for...|||Couldn't agree more with all that is posted here. Don't over complicate things. Start with FB & then a coffee before moving on to something more. Honestly, if she does not want to talk to you she...|||Yes, during times of frustration I feel the same. Before I reach out to someone I ask myself, if they aren't there for me when I need them will I be ok with helping them now?. This help me put...|||Question for my ENFJ brothers and sisters...  how do you get over a breakup especially with someone you still have great memories with and truly loved? I still my ex ESFJ boyfriend and it is been...|||I would not worry at all. He also told you not to worry - trust him! The thing is he knows to know she needs to own her feelings and that he isn't responsible for them. It is important that you...|||When I look back on when I met the ESFJ I once dated, he was immediately affectionate with me. Reached for my hand, kissed me - very obvious. When we spoke he listened to me intently & asked me some...|||<--- new picture of me. By new it is a year old, but I haven't changed in years...|||Just watched the trailer. I cannot decide from the ity-bity-clip if he's an ENFJ. Looks like an awesome movie!!|||Mr Selfridge (my newest love) Fresh Prince of Bel - Air Star Trek the Next Generation (thanks to my INFP sister) Breaking Bad (whole season is fantastic) Top Chef  I don't have a lot of time to...|||It's been a while ENFJs :)   I am curious to know how your views on relationships (romantic, familial, friendships, colleagues) has changed over the course of your life. A broad question that can...|||Not as popular as ENFPs though. I find that if their is an ENFP in the room they will outshine us. People just gravitate towards them!   I think if we need to take care of the needs of the group,...|||It used to bother me in the past, but knowing that I dislike (not hate, I cannot say I hate anyone) some people, I am comfortable knowing that others would also dislike me. I used to have a sense of...|||Great question.   -I had a little school on the block. I would make worksheets, buy all kinds of supplies for my stickers, & fix the boo-boos of the little kids. Is it surprising that I am a...|||Normally I do not like beards on men. However, when it comes to Mr. Selfridge I'd make an exception. It looks really sexy. Well groomed and suits him well. My ex also looked very hot with a beard :)...'\", \"'Loved it.  The kids are growing up and there are more adult themes in the movie.  I was also very happy to hear a Nick Cave song on the soundtrack, in the Harry/Hermione dance scene.  I've been a...|||I wonder if there are any Europeans on the site who could offer their opinions on the subject.  I think this need to be constantly smiling, constantly showing a 'positive,' 'upbeat' attitude is a...|||When I was younger, I had more energy and it would take me less time to recharge after social interactions and/or work or school days.  Now that I'm in my 40s (horrors!), I find it can take me...|||I periodically get asked this question, too.  Over the years, I've come to understand that it has more to do with my facial structure than anything.  When not smiling, I just naturally have a...|||You know you're an introvert when you'd much rather spend the day by yourself, doing your own thing, rather than trying to coordinate with a bunch of other people... all those icky people. :wink: ...|||My taste in love songs always lists to the sadder side, although sometimes a little happy sneaks in there, too.    ...|||Another atheist INFJ.  Also a secular humanist.  I've seen the damage that repressive christian moralistic thinking can do, so I choose to stay away from it.  I know not every religious person is a...|||Yeah, I wrote a paper on the Handmaid's Tale in my early college days.  I don't like her sci-fi/futuristic stuff so much, though.  The Robber Bride and Cat's Eye remain my two favorites of hers, as...|||Wow.  Well, shucks.  I don't think I've ever intimidated anyone before.  I've always kind of wanted to be perceived as a femme fatale, but I think I'm about as fatale as an after dinner mint...heh. ...|||Well, I like discussing feelings to a certain extent, but I guess not as thoroughly as some here do.  Nor am I into types so much that I think about them with every interaction I have with another...|||Introvert here.  Having dated and been in relationships with my share of both introverts and extroverts, my preference is usually for introverts like me.  When it comes to making friends, though, I...|||Did I really need to take a test to prove my atheism?  ...Ok, yeah, apparently I did.  I'm an Ardent Atheist too.  Big surprise. :dry:|||Hi kids.  Thirtiesgirl here...again.  INFJ, for those to whom that matters. :wink:  I've been futzing around some other online forums but mostly coming up lacking.  I thought I'd revisit this one...|||That's a very aquarian thing to do.  :wink:  My sun sign is Aries.  I don't know my moon or ascendant.  I had my chart done once, ages ago, and I recall there was a lot of pisces in it, so maybe...|||Ugh.  I hate that I identify with this so much.  This being RomanticEditor's original post.  It's very true for me, and I so wish it wasn't.  I've been away from this forum for a few weeks,...|||The only thing I like on a man:     The only thing I like on a woman (well, me): ...|||I would agree with this. My advice would be to date her for a while before making your decision.  Just for reference, since some people can be confused by what exactly 'dating' is, dating means doing...|||Cthulhu, you both frighten and amaze me with your mad posting skillz.  Therefore, I present this gift to you which I believe is suitable for a giant robotic cephalopod monster god.  May you enjoy it....|||I guess I missed this one the first time around.    Personal ~  * Name - What do you preferred to be called? Any nicknames? Thirtiesgirl is just fine, thanks.  * Male/Female/Trans?|||A lot of good advice here.  I'd second the advice to stay with friends or relatives and to call 911 if you or siblings feel unsafe.  But most of all, know this:  you did the right thing.  You felt...|||Ah, I see.  Well, since your gut is telling you he's a good guy, maybe give him those 3 months with you in California and see how things go.  If he starts working on finding employment in a...|||I know it might not sound helpful, but I think you look just fine the way you are.  What I see in your pics is a cute young guy.  If I was in your age group, I'd probably go for you.    Consider...|||I thought I'd post a couple of blog entries by Lesley Kinzel over at Fatshionista! on the subject of Lady Gaga.  Lesley does some pop culture analysis of Gaga's videos for Alejandro and...|||I would say this is very good advice.  The asshole you were involved with didn't love you.  He needed to control and degrade you.  That's not any kind of healthy love.  In addition, I would advise...|||Libertarian, all the way.  Government's nose, and my neighbors', do not belong in my business.|||       not the sexual explicitness that bothers me.  What bothers me is 'art' created specifically for sexual objectification.  There doesn't seem to be any other point to the pics you posted aside for...|||I don't mean to be an editorial bitch, but can we keep the hypersexualized Disney crud out of this thread?  That's not really what it's about.  And I hope to hell no one posts any H.R. Geiger,...|||I know it can seem surprising, but gay guys can be just as sexist as straight guys and have certain beliefs about how women should present themselves.  I had a close gay guy friend a few years ago...|||  Originally written by Galaxie 500, Dean Wareham's other band.|||Love it!  Thanks for sharing!     ...'Scuse me.  Ahem.  Beetlejuice, Beetlejuice, Beetlejuice.|||Ooo, pretty.  ...And yay for Heronymous Bosch (xToXiCx posted).  For those of you who like children's book drawings, particularly of fairies & c., you might enjoy Australian illustrator Ida Rentoul...|||I love architecture, too.  Specifically Antonio Gaudi and Frank Lloyd Wright.  Gaudi   ...|||I'm also a fan of photography, particularly Diane Arbus.  I love some of the unique people she used as photographic subjects. ...|||I met my friend Alicia St. Rose in college when she was an art studio major.  A few years after college, she got into photorealism and started doing pastels.  These days, she's no longer doing...|||I'm also a fan of current modern painters, like Camille Rose Garcia:   ...|||I'm a museum-goer and art lover, so I thought it might be nice to start a thread for art work you love.  Not member-created art work, but art work you love created by other people.  This can include...|||I wouldn't necessarily advise staying away from him, but limit your time with him.  As I wrote above, if he's interested, he needs to step up and take action instead of doing all these...|||If the guy is really serious about finding a date (although I have my reservations about dating people you work with), he needs to approach his interest directly and ask her to lunch or out for...|||I've never had anyone tell me that I act like a fictional character, except for an ex-boyfriend who told me that I reminded him of Daria's friend Jane, from the Daria cartoon on Mtv.  He was also...|||Fargo Miller's Crossing Cabaret  Honorable mention: O Brother, Where Art Thou?; Chicago (yeah, I like the Coens ...and the '30s)|||As an English lit major in college who later went on to get her MA in educational counseling, I say go for it.  If I'd had the presence of mind to study two things I enjoyed in college, instead of...|||Throwing Muses, Colder, from their album House Tornado.  There aren't any good video clips of this on Youtube, so I'll post a link to an mp3: ...|||Fluevogs.  I heart them.     worked in education since 2000.  I've been a substitute teacher and full-time teacher for the Los Angeles Unified School District.  I'm now a school counselor, which I've been doing since 2005. ...|||I'm a secular humanist and an atheist.  I pray to the church of me.|||I'm a big Neko Case fan, ever since I saw her open for Nick Cave nearly 10 years ago.  I love her voice, and love the song you posted.  Currently listening to: YouTube - The Raveonettes - Black /...|||Ugh.  I hate this.  Sometimes when I go out for drinks with friends and they get a little tipsy, I'll tell them to take it easy and get ok, mom back in return.  Said with large amounts of sarcasm...|||I'll repeat what I wrote in the INTJ forum, since I'm still on the fence between TJ or FJ.  As a thirtiesgirl, I love 1920s and '30s style and decor.  I love the  drapey and dramatic fashions, and...|||I'm still trying to decide if I'm an INFJ.  As I've written elsewhere on the forum, I recently took a Myers-Briggs test and was typed as an INTJ.  I've gotten that result before on other quickie...'\", \"'Only the best video game soundtrack ever    too find war a fascinating subject to study and observe, but I'd never join an army because I believe the government abuses their power over you even more if you do. They may pay you slightly more...|||I like to cook. I think it's fun to learn new recipes and change them to my tastes, plus I find that if you put some effort into preparing your food, it appears to taste better. That being said, I do...|||I don't see the point in visiting the grave of a loved one, though I've visited graveyards because it can conjure a pensive mood in regards to death and loss.|||Has anyone really been far even as decided to use even go want to do look more like?|||Your mom.  Something you're likely to find in Africa.|||I can definitely relate to your story. It can be really hard to stay motivated when you feel misunderstood.  First off, drop the medication. It has side effects which will make you feel shittier...|||Stocking shelves for the weekend at a supermarket every friday evening, together with a friend. I was about 16.  Since we came in when everyone was almost at the end of their work day, they didn't...|||rejected commercialized education  INTP|||I think it's utterly ridiculous. In a romantic relationship of any type, both parties should strive to treat eachother as equals.|||stopped reading there|||I tried that sort of thing for a few months, but after 3 of these encounters I decided it gave me little satisfaction and stopped doing it.|||- have murderous thoughts when you see someone using a word wrongly  - cry when someone calls out your flawed logic  - like cats  - attract crazy people who mistake our open-mindedness for...|||>2016 >worrying about politics  You can change how these thieves and liars operate, simply by not playing by their rules. There's no use to crying about elections when you keep partaking in the...|||unlearn everything they crammed into your poor head.|||have some of that next level futuristic stuff (might wanna put some headphones on)      ...|||not sure about these types, but here's what I came up with:  Mother - ESFJ Father - XSTJ Sister - INFJ|||I lean towards instrumental music for the most part, but some nicely selected vocal samples can really bring out the best in a track when used wisely and with moderation. example: ...|||only barely, the lowest audible frequency is about 20Hz|||I'm fond of low frequencies when it comes to sound waves.|||probably not, they seem too slow|||Count me in.|||Probably say yeah sure and never follow through.|||I try to always be respectful towards people, even if I don't like them. When people start to annoy me though, I actively start to break away from them (by reducing my input into conversation to...|||Been putting far to many hours into Unturned. Mainly because it runs on my laptop and I don't have money for a gaming pc and games.|||500666  just thinking about kittens and the purpose of my existence|||I had my first girlfriend at 17 (we just went on 1 date and decided to be together) and I tried the whole dating thing for the first time at 25, in the sense that I was going out with girls and...|||1. Do you do it? I avoid it 2. How often? Only when I'm really hungry and there are no other options 3. Do you enjoy it? No, I don't feel at ease in these situations for many reasons 4. What...|||For the most part quiet and observant, trying to make sense of my classmates' immaturity on many levels. Had no true friends at school, only some people who I hung out with out of boredom. Schoolwork...|||I'd guess about 75yrs, depending on health conditions and accidental contact with stray humans.|||Abracadabra I also have trouble maintaining the habit of doing full yoga routines, but it does work greatly.  As for your statement on INTPs naturally meditating all the time when thinking,...|||OneMind In my opinion, Locke qualifies as an INTP. He most definitely utilizes his intuition a lot and takes things as they come without judging, so ISTJ just doesn't seem right for him.|||Pantheism, yo.|||I'm open to the idea of having kids, but I'm not the kind of person to think it's absolutely necessary to have them just to fit in with society's expectations. If I'm ever having kids, it'll have to...|||appear in people's dreams and spout random fake prophecies so they'll take radical action for no reason|||I would nod at them in an understanding way, maybe offer a puff of my joint if they seemed particularly cool.|||1. What is a good person like to you? Open minded and open hearted. Nurturing and stimulating to people around them. 2. Would you consider yourself to be a good person? Getting there, my mind is...|||This. Secluded places in general attract me. I also enjoy wandering the streets late at night.|||Do I study philosophy? I AM PHILOSOPHY|||I like yoga because it doesn't require anything other than my own body to practice. Other than that I don't have a car so I bike around a lot. Competitive sports aren't really fun to me.|||I dislike organized religion as a rule, but over the past few years I've been exploring spirituality. After learning from multiple religions and philosophies, I'd define myself as a pantheist (the...|||Burial feels are the best feels    Also, Chopin   trick that usually works for me is being the DJ at said nightclub|||lol jobs.|||exactly|||I always had trouble memorizing stupid stuff like vocabulary. Languages are meant to be learned through immersion and experience, just like most other things. Fuck schools, choose your own learning...|||it's gotten me laid a few times so far without really spending a lot of time on there and they were pretty interesting people too. hell, i might even have found someone on there who i'd consider gf...|||here's some future minimalistic stuff I really like (use headphones pls)      ...|||I don't cry much at all, but the other day I was watching Chaplin's speech in The Great Dictator for some reason and it hit me hard while my shields were down. It's mostly things like that that make...|||I don't cry very often, but I do have a few things that get my mood really low really fast:  1. injustice 2. ignorance 3. witnessing great selfishness 4. being misunderstood 5. being judged in...'\"]\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n",
      "Predicted Personality Type: F\n"
     ]
    }
   ],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id = '16g474hdNsaNx0_SnoKuqj2BuwSEGdnbt'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('training_data.csv')  \n",
    "\n",
    "id = '1-7hj0sF3Rc5G6POKdkpbDXm_Q6BWFDPU'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('testing_data.csv')  \n",
    "\n",
    "import pandas as pd\n",
    "training_data = pd.read_csv(\"/content/training_data.csv\")\n",
    "testing_data = pd.read_csv(\"/content/testing_data.csv\")\n",
    "\n",
    "training_posts=training_data['posts'].tolist()\n",
    "training_labels=training_data['type'].tolist()\n",
    "testing_posts=testing_data['posts'].tolist()\n",
    "testing_labels=testing_data['type'].tolist()\n",
    "\n",
    "import re\n",
    "training_posts_no_url, testing_posts_no_url = [], []\n",
    "for i in training_posts:\n",
    "    result = re.sub(r\"http\\S+\", \"\", i)\n",
    "    training_posts_no_url.append(result)\n",
    "for j in testing_posts:\n",
    "    result = re.sub(r\"http\\S+\", \"\", j)\n",
    "    testing_posts_no_url.append(result)\n",
    "print(testing_posts_no_url[:5])\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as sw\n",
    "stop_words = sw.words('english')\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def remove_number(x):\n",
    "    x =  re.sub(r'[0-9]+', '', x)\n",
    "    return x\n",
    "def remove_punctuation_re(x):\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    return x\n",
    "def pre_process(input_list):\n",
    "    # Converting to lower case\n",
    "    lower = [s.lower() for s in input_list]\n",
    "    # Removing number \n",
    "    remove_num = [remove_number(s) for s in lower]\n",
    "    # Removing punctuation\n",
    "    remove_pun = [remove_punctuation_re(s) for s in remove_num]\n",
    "    # Tokenization \n",
    "    Tokenized = [word_tokenize(s) for s in remove_pun]\n",
    "    # Removing stop words\n",
    "    remove_sw = []\n",
    "    for tokens in Tokenized:\n",
    "        filtered_sentence = [w for w in tokens if not w in stop_words]\n",
    "        remove_sw.append(filtered_sentence)\n",
    "    # Stemming\n",
    "    result = []\n",
    "    for tokens in remove_sw:\n",
    "        stemmed = [stemmer.stem(s) for s in tokens]\n",
    "        result.append(stemmed)\n",
    "    return result\n",
    "\n",
    "unique_labels = np.unique(training_labels)\n",
    "lEnc = LabelEncoder()\n",
    "training_labels_encoded = lEnc.fit_transform(training_labels)\n",
    "testing_labels_encoded = lEnc.transform(testing_labels)\n",
    "n_class = len(unique_labels)\n",
    "\n",
    "\n",
    "training_posts_no_url_processed = pre_process(training_posts_no_url)\n",
    "testing_posts_no_url_processed = pre_process(testing_posts_no_url)\n",
    "\n",
    "emb_list = []\n",
    "for i in training_posts_no_url_processed:\n",
    "    emb_list.append(i)\n",
    "for j in testing_posts_no_url_processed:\n",
    "    emb_list.append(j)\n",
    "\n",
    "# Download Embedding model from gensim\n",
    "import gensim.downloader as api\n",
    "word_emb_model_2 = api.load(\"glove-twitter-100\")\n",
    "\n",
    "word_set = set() \n",
    "for sent in emb_list:\n",
    "    for word in sent:\n",
    "        word_set.add(word)\n",
    "\n",
    "word_set.add('[PAD]')\n",
    "word_set.add('[UNKNOWN]')\n",
    "\n",
    "word_list = list(word_set) \n",
    "word_list.sort()\n",
    "word_index = {}\n",
    "ind = 0\n",
    "for word in word_list:\n",
    "    word_index[word] = ind\n",
    "    ind += 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "emb_dim = word_emb_model_2.vector_size\n",
    "emb_table = []\n",
    "for i, word in enumerate(word_list):\n",
    "    if word in word_emb_model_2:\n",
    "        emb_table.append(word_emb_model_2[word])\n",
    "    else:\n",
    "        emb_table.append([0]*emb_dim)\n",
    "emb_table = np.array(emb_table)\n",
    "    \n",
    "# Padding & Encoding\n",
    "seq_length = 100\n",
    "def encode_and_add_padding(sentences, seq_length, word_index):\n",
    "    sent_encoded = []\n",
    "    for sent in sentences:\n",
    "        temp_encoded = [word_index[word] if word in word_index else word_index['[UNKNOWN]'] for word in sent]\n",
    "        if len(temp_encoded) < seq_length:\n",
    "            temp_encoded += [word_index['[PAD]']] * (seq_length - len(temp_encoded))\n",
    "        sent_encoded.append(temp_encoded[:100])\n",
    "    return sent_encoded\n",
    "\n",
    "train_pad_encoded_no_url = encode_and_add_padding(training_posts_no_url_processed, seq_length, word_index )\n",
    "test_pad_encoded_no_url = encode_and_add_padding(testing_posts_no_url_processed, seq_length, word_index )\n",
    "\n",
    "vocab_size = len(word_list)\n",
    "total_epoch = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(emb_table))\n",
    "        self.emb.weight.requires_grad = False\n",
    "        n_hidden = 50\n",
    "        self.lstm = nn.LSTM(emb_dim, n_hidden, batch_first =True, bidirectional=True)\n",
    "        self.linear = nn.Linear(n_hidden*2, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
    "        z = self.linear(hidden_out)\n",
    "        return z\n",
    "\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#@title Personality Type Prediction\n",
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "id = '1PgbZlcjAvMIRcqLvq5jOqyCmpDmF_ZLf'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('bi_LSTM.pt') \n",
    "text = \"\" #@param {type:\"string\"}\n",
    "text = re.sub(r\"http\\S+\", \"\", text)\n",
    "text = pre_process([text])\n",
    "text_input = encode_and_add_padding(\n",
    "    text, \n",
    "    seq_length, \n",
    "    word_index)\n",
    "model = torch.load(\n",
    "     '/content/bi_LSTM.pt'\n",
    "    )\n",
    "input_torch = torch.from_numpy(\n",
    "    np.array(text_input)).to(device)\n",
    "outputs = model(input_torch) \n",
    "predicted = torch.argmax(outputs, -1)\n",
    "output = \"T\" if predicted.cpu().numpy()[0] == 1 else \"F\"\n",
    "print(\"Predicted Personality Type: {}\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfv8rWTKPzeb"
   },
   "source": [
    "# Object Oriented Programming codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS23AjBRSZaX"
   },
   "source": [
    "*You can use multiple code snippets. Just add more if needed* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hVmx4E52dXS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "jlai6523_COMP5046_Ass1_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
